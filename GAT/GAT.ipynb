{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fe2213",
   "metadata": {},
   "source": [
    "# GAT for EEG classification\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00a97c",
   "metadata": {},
   "source": [
    "In this notebook we will implement a Graph Attention Network (GAT) for EEG classification using PyTorch Geometric.  \n",
    "This notebook contains the following sections:\n",
    "1. **Dataset loading**: Load the EEG dataset and apply necessary preprocessing.\n",
    "2. **GAT implementation**: Define the GAT model architecture and training loop.\n",
    "3. **Submission**: Prepare the submission file with predictions.\n",
    "4. **K-Fold evaluation**: Implement K-Fold cross-validation to evaluate the model's performance.\n",
    "5. **Interpretability**: Visualize the attention weights to understand the model's focus on different EEG channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522eb95",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a256ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seiz_eeg.dataset import EEGDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "BASE_DIR = \"/home/stnikoli/nml_project/GAT\"\n",
    "\n",
    "sys.path.append(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4a1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to change this according to where you store the data folder\n",
    "# Inside your data folder, you should have the following structure:\n",
    "# data\n",
    "# ├── train\n",
    "# │   ├── signals/\n",
    "# │   ├── segments.parquet\n",
    "# │-- test\n",
    "#     ├── signals/\n",
    "#     ├── segments.parquet\n",
    "\n",
    "data_path = \"/home/stnikoli/nml_project/data\"\n",
    "\n",
    "DATA_ROOT = Path(data_path)\n",
    "clips_tr = pd.read_parquet(DATA_ROOT / \"train/segments.parquet\")\n",
    "\n",
    "# Split the dataset by the 'patient' column\n",
    "patients = clips_tr['signals_path'].unique()\n",
    "train_patients, val_patients = train_test_split(patients, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_clips = clips_tr[clips_tr['signals_path'].isin(train_patients)]\n",
    "val_clips = clips_tr[clips_tr['signals_path'].isin(val_patients)]\n",
    "\n",
    "# split the clips into training and validation sets\n",
    "# train_clips, val_clips = train_test_split(clips_tr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62593f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hjorth_features import create_hjorth_transforms\n",
    "\n",
    "_hjorth_transform, _ = create_hjorth_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f21a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_filtering(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute FFT and only keep\"\"\"\n",
    "    x = np.abs(np.fft.fft(x, axis=0))\n",
    "    x = np.log(np.where(x > 1e-8, x, 1e-8))\n",
    "\n",
    "    win_len = x.shape[0]\n",
    "    # Only frequencies b/w 0.5 and 30Hz\n",
    "    return x[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
    "\n",
    "bp_filter = signal.butter(4, (0.5, 30), btype=\"bandpass\", output=\"sos\", fs=250)\n",
    "\n",
    "\n",
    "def time_filtering(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Filter signal in the time domain\"\"\"\n",
    "    return signal.sosfiltfilt(bp_filter, x, axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69253d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(\n",
    "        train_clips,\n",
    "        signals_root=DATA_ROOT / \"train\",\n",
    "        signal_transform=_hjorth_transform,\n",
    "        prefetch=True,  # If your compute does not allow it, you can use `prefetch=False`\n",
    "    )\n",
    "\n",
    "val_dataset = EEGDataset(\n",
    "        val_clips,\n",
    "        signals_root=DATA_ROOT / \"train\",\n",
    "        signal_transform=_hjorth_transform,\n",
    "        prefetch=True,  # If your compute does not allow it, you can use `prefetch=False`\n",
    "    )\n",
    "\n",
    "loader_tr = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=512,\n",
    "    )\n",
    "\n",
    "loader_val = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a783b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals shape: torch.Size([512, 15, 19])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader_tr:\n",
    "    signals, labels = batch\n",
    "    break\n",
    "print(f\"Signals shape: {signals.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e31d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "671a2821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones count: 2012, Zeros count: 8155\n"
     ]
    }
   ],
   "source": [
    "# count ones and zeros in the training set\n",
    "ones_count = np.sum([x[1] for x in train_dataset])\n",
    "zeros_count = len(train_dataset) - ones_count\n",
    "print(f\"Ones count: {ones_count}, Zeros count: {zeros_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716558c",
   "metadata": {},
   "source": [
    "## GAT implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92bcd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assume DATA_ROOT, _hjorth_transform, train_clips, and val_clips are defined\n",
    "# Assume device is also defined (e.g., device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# ======================================================================\n",
    "# 1. Refined GAT Model Definition\n",
    "#    - The forward method now correctly accepts edge_index and batch.\n",
    "#    - The model no longer stores the adjacency matrix, simplifying its design.\n",
    "#    - The output dimension is set to 1, which is correct for BCEWithLogitsLoss.\n",
    "# ======================================================================\n",
    "\n",
    "class GATClassifier(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes=1, edge_index_template=None, evaluate=False):\n",
    "        super(GATClassifier, self).__init__()\n",
    "        \n",
    "        # GAT layers\n",
    "        self.conv1 = GATConv(num_node_features, 32, heads=4, dropout=0.5)\n",
    "        self.conv2 = GATConv(32 * 4, 64, heads=4, dropout=0.5)\n",
    "        \n",
    "        # Pooling and final classification layer\n",
    "        self.pool = global_mean_pool\n",
    "        self.fc = nn.Linear(64 * 4, num_classes)\n",
    "\n",
    "        self.edge_index_template = edge_index_template\n",
    "        self.evaluate = evaluate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The edge_index is now passed directly here\n",
    "        B, Nf, N = x.shape\n",
    "\n",
    "        # --- On-the-fly Batch Conversion ---\n",
    "        x_pyg = x.reshape(-1, Nf)\n",
    "        batch_vector = torch.arange(B, device=device).repeat_interleave(N)\n",
    "        edge_indices = [self.edge_index_template + i * N for i in range(B)]\n",
    "        edge_index = torch.cat(edge_indices, dim=1)\n",
    "        x = x_pyg.to(device)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x, attention_weights = self.conv2(x, edge_index, return_attention_weights=True)\n",
    "        \n",
    "        x = self.pool(x, batch_vector)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        if self.evaluate:\n",
    "            # For evaluation, we return the raw logits\n",
    "            return x\n",
    "        return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62e0da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 2. Streamlined Graph Creation\n",
    "#    - This single function now handles loading distances and creating the\n",
    "#      sparse `edge_index` directly, removing redundant steps.\n",
    "# ======================================================================\n",
    "\n",
    "def create_graph_edge_index(distances_path, distance_threshold=None):\n",
    "    \"\"\"\n",
    "    Loads electrode distances and creates a sparse graph edge_index.\n",
    "    \"\"\"\n",
    "    # Load distance matrix, assuming 19 electrodes\n",
    "    distances = np.genfromtxt(distances_path, skip_header=1, delimiter=',')[:, -1].reshape(19, 19)\n",
    "    distances = torch.tensor(distances, dtype=torch.float32)\n",
    "    \n",
    "    if distance_threshold is None:\n",
    "        # Use an adaptive threshold based on the median distance\n",
    "        distance_threshold = torch.median(distances[distances > 0])\n",
    "    \n",
    "    # Create adjacency matrix and convert directly to edge_index\n",
    "    adj_matrix = (distances <= distance_threshold)\n",
    "    edge_index = adj_matrix.nonzero(as_tuple=False).t().contiguous()\n",
    "    \n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "955fe0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# 3. Training Loop (Unchanged, as it was already correct)\n",
    "# ======================================================================\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch using a standard DataLoader.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        x_batch = x_batch.float().to(device)\n",
    "        y_batch = y_batch.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # This call now matches the corrected GATClassifier.forward signature\n",
    "        logits, _ = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d03e4dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1], device=device))\n",
    "criterion(torch.tensor([0.0, 0.0, 0.0, 0.0], device=device), torch.tensor([1.0, 1.0, 1.0, 1.0], device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a159208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def test_epoch(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model on the test set for one epoch.\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():  # Deactivate autograd for evaluation\n",
    "        for x_batch, y_batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            # x_batch shape: (batch_size, num_nodes, num_features)\n",
    "            # y_batch shape: (batch_size)\n",
    "            \n",
    "            x_batch = x_batch.float().to(device)\n",
    "            y_batch_labels = y_batch.float() # Keep labels on CPU for sklearn\n",
    "            y_batch_loss = y_batch_labels.unsqueeze(1).to(device) # Send to device for loss calc\n",
    "\n",
    "            # Forward pass\n",
    "            logits, _ = model(x_batch)\n",
    "            loss = criterion(logits, y_batch_loss)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # --- Calculate Predictions for Metrics ---\n",
    "            # Apply sigmoid to logits to get probabilities\n",
    "            probs = torch.sigmoid(logits).cpu()\n",
    "            # Get binary predictions (0 or 1) using a 0.5 threshold\n",
    "            preds = (probs > 0.5).float().squeeze(1)\n",
    "            \n",
    "            # Append batch results to lists for epoch-wide calculation\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(y_batch_labels.numpy())\n",
    "            all_ids.extend(y_batch.numpy())\n",
    "\n",
    "    # Calculate metrics for the entire epoch\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0, average='macro')\n",
    "    \n",
    "    return avg_loss, f1, precision, recall, all_preds, all_labels, all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98a6d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the simplified model\n",
    "# Create the single graph structure ONCE\n",
    "single_graph_edge_index = create_graph_edge_index(\n",
    "    distances_path=DATA_ROOT / \"distances_3d.csv\",\n",
    "    distance_threshold = 0\n",
    ")\n",
    "# Move the single-graph edge_index to the correct device once\n",
    "edge_index_template = single_graph_edge_index.to(device)\n",
    "model = GATClassifier(num_node_features=15, num_classes=1, edge_index_template=edge_index_template) # num_classes=1 for BCEWithLogitsLoss\n",
    "\n",
    "# Or load a pre-trained model if available\n",
    "# model.load_state_dict(torch.load(\"/home/stnikoli/nml_project/GAT/gat_model_epoch_300.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db35cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training Setup ---\n",
    "class_weight = 4\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weight], device=device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54aad9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 85.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Val Loss: 5.0768, F1: 0.4444, Precision: 0.5806, Recall: 0.6199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Train Loss: 45.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Val Loss: 5.7385, F1: 0.5773, Precision: 0.6125, Recall: 0.6913\n",
      "Model saved at epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Train Loss: 60.9941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Val Loss: 4.7458, F1: 0.5956, Precision: 0.6033, Recall: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Train Loss: 27.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Val Loss: 3.8869, F1: 0.5556, Precision: 0.5963, Recall: 0.6640\n",
      "Model saved at epoch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, Train Loss: 19.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, Val Loss: 3.0083, F1: 0.5607, Precision: 0.5955, Recall: 0.6620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, Train Loss: 26.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, Val Loss: 2.4773, F1: 0.5164, Precision: 0.5884, Recall: 0.6485\n",
      "Model saved at epoch 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Train Loss: 16.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Val Loss: 1.8765, F1: 0.6091, Precision: 0.6108, Recall: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Train Loss: 7.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Val Loss: 1.7016, F1: 0.5857, Precision: 0.5908, Recall: 0.6422\n",
      "Model saved at epoch 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Train Loss: 4.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Val Loss: 1.3161, F1: 0.6126, Precision: 0.6173, Recall: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Train Loss: 2.5249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Val Loss: 1.1478, F1: 0.5796, Precision: 0.5834, Recall: 0.5768\n",
      "Model saved at epoch 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, Train Loss: 2.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550, Val Loss: 1.1497, F1: 0.5019, Precision: 0.5610, Recall: 0.6038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600, Train Loss: 2.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600, Val Loss: 1.2185, F1: 0.2267, Precision: 0.5426, Recall: 0.5192\n",
      "Model saved at epoch 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650, Train Loss: 1.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650, Val Loss: 1.0987, F1: 0.3273, Precision: 0.4990, Recall: 0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700, Train Loss: 2.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700, Val Loss: 1.0884, F1: 0.3914, Precision: 0.5179, Recall: 0.5269\n",
      "Model saved at epoch 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750, Train Loss: 2.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750, Val Loss: 1.1028, F1: 0.3666, Precision: 0.5207, Recall: 0.5282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800, Train Loss: 1.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800, Val Loss: 1.1063, F1: 0.4426, Precision: 0.5652, Recall: 0.6000\n",
      "Model saved at epoch 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850, Train Loss: 1.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850, Val Loss: 1.1091, F1: 0.3516, Precision: 0.5529, Recall: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900, Train Loss: 2.2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900, Val Loss: 1.1061, F1: 0.4205, Precision: 0.5533, Recall: 0.5793\n",
      "Model saved at epoch 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950, Train Loss: 1.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950, Val Loss: 1.1204, F1: 0.6007, Precision: 0.6016, Recall: 0.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Train Loss: 2.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Val Loss: 1.1231, F1: 0.4423, Precision: 0.5726, Recall: 0.6094\n",
      "Model saved at epoch 1000\n",
      "Training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 4. Main Execution Block\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):    \n",
    "    train_loss = train_epoch(model, loader_tr, criterion, optimizer, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
    "        # Validation\n",
    "        val_loss, f1, precision, recall, _, _, _ = test_epoch(model, loader_val, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}, Val Loss: {val_loss:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    # save model every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"/home/stnikoli/nml_project/GAT/gat_model_epoch_{epoch + 1}.pth\")\n",
    "        print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a90d76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAHUCAYAAAAwUBnrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJn0lEQVR4nO3dd3hUVf4/8Pf0ZNILqYTQawAp0qt0xIauig1WXCusLLr2gi6C+vta1oYdVCzYFxURECkaOoL0GmoSQnqfen5/hJncO3OnhUAmyfv1PDxP5s6dO2eSK+bN55zPUQkhBIiIiIiIiMhv6oYeABERERERUWPDIEVERERERBQgBikiIiIiIqIAMUgREREREREFiEGKiIiIiIgoQAxSREREREREAWKQIiIiIiIiChCDFBERERERUYAYpIiIiIiIiALEIEVEdIGoVCq//qxZs+a83mfOnDlQqVR1eu2aNWvqZQzn895ff/31RX/vuti4cSP+9re/ITk5GXq9HklJSbjuuuuwYcOGhh6am2PHjnm95+bMmdPQQ0Tr1q0xadKkhh4GEVGdaRt6AERETZXrL9j/+c9/8Ntvv2H16tWy4127dj2v97njjjswfvz4Or22d+/e2LBhw3mPoal7/fXXMWvWLPTr1w8vvvgi0tPTceLECbz55psYMmQI/vvf/2LGjBkNPUw3M2fOxE033eR2vGXLlg0wGiKipoVBiojoAhkwYIDscYsWLaBWq92Ou6qsrITRaPT7fVq2bFnnX4wjIyN9jqe5++OPPzBr1ixMnDgR3333HbTa2v913njjjbjmmmtw//33o1evXhg8ePBFG1dVVRVCQkK8ViNbtWrFny8R0QXCqX1ERA1oxIgRyMjIwLp16zBo0CAYjUbcfvvtAIAlS5Zg7NixSE5ORmhoKLp06YJHHnkEFRUVsmsoTe1zTJtavnw5evfujdDQUHTu3Bkffvih7DylqX3Tpk1DeHg4Dh8+jIkTJyI8PBxpaWl44IEHYDKZZK8/deoUrrvuOkRERCA6Oho333wztmzZApVKhUWLFtXL92j37t246qqrEBMTg5CQEFxyySX46KOPZOfY7XbMnTsXnTp1QmhoKKKjo9GjRw/897//dZ5z9uxZ3HnnnUhLS4PBYECLFi0wePBgrFq1yuv7z58/HyqVCgsWLJCFKADQarV46623oFKp8PzzzwMAvv/+e6hUKvz6669u11qwYAFUKhX++usv57GtW7fiyiuvRGxsLEJCQtCrVy98+eWXstctWrQIKpUKK1aswO23344WLVrAaDS6/TzqwnEPrl+/HgMGDEBoaChSU1Px5JNPwmazyc4tLCzEvffei9TUVOj1erRt2xaPP/642zjsdjtef/11XHLJJc6fx4ABA7B06VK39/d1j1ZWVuLBBx9EmzZtEBISgtjYWPTt2xeff/75eX92IqLzwYoUEVEDy8nJwS233IKHHnoI8+bNg1pd829chw4dwsSJEzFr1iyEhYVh//79eOGFF7B582a36YFKdu7ciQceeACPPPIIEhMT8f7772P69Olo3749hg0b5vW1FosFV155JaZPn44HHngA69atw3/+8x9ERUXhqaeeAgBUVFRg5MiRKCwsxAsvvID27dtj+fLluOGGG87/m3LOgQMHMGjQICQkJOC1115DXFwcFi9ejGnTpuHMmTN46KGHAAAvvvgi5syZgyeeeALDhg2DxWLB/v37UVxc7LzWrbfeiu3bt+O5555Dx44dUVxcjO3bt6OgoMDj+9tsNvz222/o27evx6pfWloa+vTpg9WrV8Nms2HSpElISEjAwoULMWrUKNm5ixYtQu/evdGjRw8AwG+//Ybx48ejf//+ePvttxEVFYUvvvgCN9xwAyorKzFt2jTZ62+//XZcfvnl+OSTT1BRUQGdTuf1+2e322G1Wt2OuwbC3Nxc3HjjjXjkkUfw7LPP4qeffsLcuXNRVFSEN954AwBQXV2NkSNH4siRI3jmmWfQo0cPrF+/HvPnz8eOHTvw008/Oa83bdo0LF68GNOnT8ezzz4LvV6P7du349ixY7L39ecenT17Nj755BPMnTsXvXr1QkVFBXbv3u3150ZEdFEIIiK6KKZOnSrCwsJkx4YPHy4AiF9//dXra+12u7BYLGLt2rUCgNi5c6fzuaefflq4/nWenp4uQkJCxPHjx53HqqqqRGxsrLjrrrucx3777TcBQPz222+ycQIQX375peyaEydOFJ06dXI+fvPNNwUA8fPPP8vOu+uuuwQAsXDhQq+fyfHeX331lcdzbrzxRmEwGMSJEydkxydMmCCMRqMoLi4WQggxadIkcckll3h9v/DwcDFr1iyv57jKzc0VAMSNN97o9bwbbrhBABBnzpwRQggxe/ZsERoa6hyfEELs3btXABCvv/6681jnzp1Fr169hMVikV1v0qRJIjk5WdhsNiGEEAsXLhQAxG233ebXuLOysgQAj3/Wr1/vPNdxD/7vf/+TXeMf//iHUKvVznvo7bffVrwvXnjhBQFArFixQgghxLp16wQA8fjjj3sdo7/3aEZGhrj66qv9+txERBcTp/YRETWwmJgYXHbZZW7Hjx49iptuuglJSUnQaDTQ6XQYPnw4AGDfvn0+r3vJJZegVatWzschISHo2LEjjh8/7vO1KpUKV1xxhexYjx49ZK9du3YtIiIi3BpdTJkyxef1/bV69WqMGjUKaWlpsuPTpk1DZWWls6FHv379sHPnTtx777345ZdfUFpa6natfv36YdGiRZg7dy42btwIi8VSb+MUQgCAc4rl7bffjqqqKixZssR5zsKFC2EwGJzNHw4fPoz9+/fj5ptvBgBYrVbnn4kTJyInJwcHDhyQvc+1114b0Ljuv/9+bNmyxe3PJZdcIjsvIiICV155pezYTTfdBLvdjnXr1gGo+VmEhYXhuuuuk53nqJo5pjL+/PPPAID77rvP5/j8uUf79euHn3/+GY888gjWrFmDqqoq/z48EdEFxiBFRNTAkpOT3Y6Vl5dj6NCh2LRpE+bOnYs1a9Zgy5Yt+PbbbwHAr18m4+Li3I4ZDAa/Xms0GhESEuL22urqaufjgoICJCYmur1W6VhdFRQUKH5/UlJSnM8DwKOPPor/+7//w8aNGzFhwgTExcVh1KhR2Lp1q/M1S5YswdSpU/H+++9j4MCBiI2NxW233Ybc3FyP7x8fHw+j0YisrCyv4zx27BiMRiNiY2MBAN26dcOll16KhQsXAqiZIrh48WJcddVVznPOnDkDAHjwwQeh0+lkf+69914AQH5+vux9lL4X3rRs2RJ9+/Z1+xMeHi47T+lnlpSUBKD2e1xQUICkpCS39XgJCQnQarXO886ePQuNRuN8vTf+3KOvvfYaHn74YXz//fcYOXIkYmNjcfXVV+PQoUM+r09EdCExSBERNTClrmurV69GdnY2PvzwQ9xxxx0YNmwY+vbti4iIiAYYobK4uDhnGJDyFkzq8h45OTlux7OzswHUBB2gZs3P7NmzsX37dhQWFuLzzz/HyZMnMW7cOFRWVjrPffXVV3Hs2DEcP34c8+fPx7fffuu2DklKo9Fg5MiR2Lp1K06dOqV4zqlTp7Bt2zZcdtll0Gg0zuN///vfsXHjRuzbtw/Lly9HTk4O/v73vzufd4z90UcfVawaKVWO6rpfmC/efo6OsOP4eTuqbw55eXmwWq3Oz9OiRQvYbLZ6uw/CwsLwzDPPYP/+/cjNzcWCBQuwceNGt4opEdHFxiBFRBSEHL8wGwwG2fF33nmnIYajaPjw4SgrK3NO5XL44osv6u09Ro0a5QyVUh9//DGMRqNia+/o6Ghcd911uO+++1BYWOjW4ACoaQs+Y8YMjBkzBtu3b/c6hkcffRRCCNx7771uXexsNhvuueceCCHw6KOPyp6bMmUKQkJCsGjRIixatAipqakYO3as8/lOnTqhQ4cO2Llzp2LV6GIG57KyMreOep999hnUarWz6cOoUaNQXl6O77//Xnbexx9/7HweACZMmACgpkNhfUtMTMS0adMwZcoUHDhwwBmSiYgaArv2EREFoUGDBiEmJgZ33303nn76aeh0Onz66afYuXNnQw/NaerUqXjllVdwyy23YO7cuWjfvj1+/vln/PLLLwDg7D7oy8aNGxWPDx8+HE8//TR+/PFHjBw5Ek899RRiY2Px6aef4qeffsKLL76IqKgoAMAVV1yBjIwM9O3bFy1atMDx48fx6quvIj09HR06dEBJSQlGjhyJm266CZ07d0ZERAS2bNmC5cuXY/LkyV7HN3jwYLz66quYNWsWhgwZghkzZqBVq1bODXk3bdqEV199FYMGDZK9Ljo6Gtdccw0WLVqE4uJiPPjgg27fk3feeQcTJkzAuHHjMG3aNKSmpqKwsBD79u3D9u3b8dVXX/n1PfTkxIkTit/fFi1aoF27ds7HcXFxuOeee3DixAl07NgRy5Ytw3vvvYd77rnHuYbptttuw5tvvompU6fi2LFj6N69O37//XfMmzcPEydOxOjRowEAQ4cOxa233oq5c+fizJkzmDRpEgwGA/78808YjUbMnDkzoM/Qv39/TJo0CT169EBMTAz27duHTz75BAMHDgxovzUionrXsL0uiIiaD09d+7p166Z4fmZmphg4cKAwGo2iRYsW4o477hDbt29364jnqWvf5Zdf7nbN4cOHi+HDhzsfe+ra5zpOT+9z4sQJMXnyZBEeHi4iIiLEtddeK5YtW6bYBc6V4709/XGMadeuXeKKK64QUVFRQq/Xi549e7p1BHzppZfEoEGDRHx8vNDr9aJVq1Zi+vTp4tixY0IIIaqrq8Xdd98tevToISIjI0VoaKjo1KmTePrpp0VFRYXXcTps2LBBXHfddSIxMVFotVqRkJAgJk+eLDIzMz2+ZsWKFc7Pc/DgQcVzdu7cKa6//nqRkJAgdDqdSEpKEpdddpl4++23nec4uvZt2bLFr7H66tp38803O8913INr1qwRffv2FQaDQSQnJ4vHHnvMrZtgQUGBuPvuu0VycrLQarUiPT1dPProo6K6ulp2ns1mE6+88orIyMgQer1eREVFiYEDB4offvjBeY6/9+gjjzwi+vbtK2JiYoTBYBBt27YV//rXv0R+fr5f3wsiogtFJYTLZGciIqLzMG/ePDzxxBM4ceKEx72XKHiMGDEC+fn52L17d0MPhYioUeHUPiIiqjPHZq2dO3eGxWLB6tWr8dprr+GWW25hiCIioiaNQYqIiOrMaDTilVdewbFjx2AymdCqVSs8/PDDeOKJJxp6aERERBcUp/YREREREREFiO3PiYiIiIiIAsQgRUREREREFCAGKSIiIiIiogCx2QQAu92O7OxsREREQKVSNfRwiIiIiIiogQghUFZWhpSUFK+byzNIAcjOzkZaWlpDD4OIiIiIiILEyZMnvW7lwSAFICIiAkDNNysyMrJBx2KxWLBixQqMHTsWOp2uQcdCjQPvGQoU7xkKFO8ZChTvGQpUMN0zpaWlSEtLc2YETxikAOd0vsjIyKAIUkajEZGRkQ1+E1HjwHuGAsV7hgLFe4YCxXuGAhWM94yvJT9sNkFERERERBQgBikiIiIiIqIAMUgREREREREFiGukiIiIiIh8sNlssFgsDT2MJstisUCr1aK6uho2m+2CvpdGo4FWqz3vbY8YpIiIiIiIvCgvL8epU6cghGjooTRZQggkJSXh5MmTF2VfV6PRiOTkZOj1+jpfg0GKiIiIiMgDm82GU6dOwWg0okWLFhfll/zmyG63o7y8HOHh4V43wT1fQgiYzWacPXsWWVlZ6NChQ53fj0GKiIiIiMgDi8UCIQRatGiB0NDQhh5Ok2W322E2mxESEnJBgxQAhIaGQqfT4fjx4873rAs2myAiIiIi8oGVqKalPsIagxQREREREVGAGKSIiIiIiIgCxCBFREREREQ+jRgxArNmzWroYQQNNpsgIiIiImpCfK3nmjp1KhYtWhTwdb/99lvodLo6jqrGtGnTUFxcjO+///68rhMMGKSIiIiIiJqQnJwc59dLlizBU089hQMHDjiPuXYftFgsfgWk2NjY+htkE8CpfUEopxK4/aNt+PNEUUMPhYiIiIgkhBCoNFsb5I+/GwInJSU5/0RFRUGlUjkfV1dXIzo6Gl9++SVGjBiBkJAQLF68GAUFBZgyZQpatmwJo9GI7t274/PPP5dd13VqX+vWrTFv3jzcfvvtiIiIQKtWrfDuu++e1/d37dq16NevHwwGA5KTk/HII4/AarU6n//666/RvXt3hIaGIi4uDqNHj0ZFRQUAYM2aNejXrx/CwsIQHR2NwYMH4/jx4+c1Hm9YkQpC7+7XoNBUgPWHM3Hs+csbejhEREREdE6VxYauT/3SIO+999lxMOrr59f3hx9+GC+99BIWLlwIg8GA6upq9OnTBw8//DAiIyPx008/4dZbb0Xbtm3Rv39/j9d56aWX8J///AePPfYYvv76a9xzzz0YNmwYOnfuHPCYsrOzMWnSJEybNg0ff/wx9u/fj3/84x8ICQnBnDlzkJOTgylTpuDFF1/ENddcg7KyMqxfvx5CCFitVlx99dX4xz/+gc8//xxmsxmbN2++oG3rGaSCUJGpoUdARERERE3ZrFmzMHnyZNmxBx980Pn1zJkzsXz5cnz11Vdeg9TEiRNx7733AqgJZ6+88grWrFlTpyD1wQcfIC0tDW+88QZUKhU6d+6M7OxsPPzww3jqqaeQk5MDq9WKyZMnIz09HQDQvXt3AEBhYSFKSkowadIktGvXDgDQpUuXgMcQCAapIKRSAX5WbomIiIjoIgrVabD32XEN9t71pW/fvrLHNpsNzz//PJYsWYLTp0/DZDLBZDIhLCzM63V69Ojh/NoxhTAvL69OYzp48CAGDBggqyINHjwY5eXlOHXqFHr27IlRo0ahe/fuGDduHMaOHYvrrrsOMTExiI2NxbRp0zBu3DiMGTMGo0ePxvXXX4/k5OQ6jcUfXCMVZJ5cuhd2wZ2ziYiIiIKRSqWCUa9tkD/1OU3NNSC99NJLeOWVV/DQQw9h9erV2LFjB8aNGwez2ez1Oq5NKlQqFex2e53GJIRw+4yOdWEqlQoajQYrV67Ezz//jK5du+L1119Hp06dkJWVBQBYuHAhNmzYgEGDBmHJkiXo2LEjNm7cWKex+INBKsis2HumoYdARERERM3M+vXrcdVVV+GWW25Bz5490bZtWxw6dOiijqFTp07YsGGDrKlGZmYmIiIikJqaCqAmUA0ePBjPPPMM/vzzT+j1enz33XfO83v16oVHH30UmZmZyMjIwGeffXbBxsupfUFGfQEXxBERERERKWnfvj2++eYbZGZmIiYmBi+//DJyc3MvyDqjkpIS7NixQ3YsOjoa06dPx9tvv42ZM2dixowZOHDgAJ5++mnMnj0barUamzZtwq+//oqxY8ciISEBmzZtwtmzZ9GlSxdkZWXh3XffxZVXXomUlBQcOHAABw8exG233Vbv43dgkAoyDFJEREREdLE9+eSTyMrKwrhx42A0GnHnnXfi6quvRklJSb2/15o1a9CrVy/Zsdtuuw3//e9/8eOPP+Lhhx9Gz549ERsbi+nTp+OJJ54AAERGRmLdunV49dVXUVpaivT0dLz00kuYMGECzpw5g/379+Ojjz5CQUEBkpOTMWPGDNx11131Pn4HBqkgwxxFRERERPVl2rRpmDZtmvNx69atFfejio2Nxffff+/1WmvWrJE9PnbsmNs5rpUmV4sWLcKiRYvcjtvtdpSWlmL48OHYvHmz4mu7dOmC5cuXKz6XmJgom+J3MXCNVJDRMEkREREREQU9Bqkgo2aOIiIiIiIKegxSQeZC7r5MRERERET1g0EqyLDZBBERERFR8GOQCjKc2kdEREQUfJQaNFDjVR8/zwYNUvPnz8ell16KiIgIJCQk4Oqrr8aBAwdk5wghMGfOHKSkpCA0NBQjRozAnj17ZOeYTCbMnDkT8fHxCAsLw5VXXolTp05dzI9Sb9RMUkRERERBQ6PRAADMZnMDj4TqU2VlJQBAp9PV+RoN2v587dq1uO+++3DppZfCarXi8ccfx9ixY7F3716EhYUBAF588UW8/PLLWLRoETp27Ii5c+dizJgxOHDgACIiIgAAs2bNwg8//IAvvvgCcXFxeOCBBzBp0iRs27bNefM3FsxRRERERMFDq9XCaDTi7Nmz0Ol0UKs5oetCsNvtMJvNqK6uvqDfYyEEKisrkZeXh+jo6PPKCg0apFz7wC9cuBAJCQnYtm0bhg0bBiEEXn31VTz++OOYPHkyAOCjjz5CYmIiPvvsM9x1110oKSnBBx98gE8++QSjR48GACxevBhpaWlYtWoVxo0bd9E/1/ngGikiIiKi4KFSqZCcnIysrCwcP368oYfTZAkhUFVVhdDQ0IvSfC06OhpJSUnndY2g2pDXsXNybGwsACArKwu5ubkYO3as8xyDwYDhw4cjMzMTd911F7Zt2waLxSI7JyUlBRkZGcjMzFQMUiaTCSaTyfm4tLQUAGCxWGCxWC7IZ6urYBsPBR/HPcJ7hfzFe4YCxXuGAtXU7hmVSoXWrVvDYrFwrdQFYrVakZmZiUGDBkGrvXARRaVSQavVQqPRwGq1Kp7j730bNEFKCIHZs2djyJAhyMjIAADk5uYCqNmpWCoxMdH5LwK5ubnQ6/WIiYlxO8fxelfz58/HM88843Z8xYoVMBqN5/1ZzkdFuQZAbQpftmxZww2GGpWVK1c29BCokeE9Q4HiPUOB4j1DgVq3bl1DD8G5fsqXoAlSM2bMwF9//YXff//d7TnX8p4QwmfJz9s5jz76KGbPnu18XFpairS0NIwdOxaRkZF1GH39ee/4BpyqKHM+njhxYgOOhhoDi8WClStXYsyYMee1YJKaD94zFCjeMxQo3jMUqGC6Zxyz1XwJiiA1c+ZMLF26FOvWrUPLli2dxx3zFnNzc5GcnOw8npeX56xSJSUlwWw2o6ioSFaVysvLw6BBgxTfz2AwwGAwuB3X6XQN/oNz7drX0OOhxiMY7l9qXHjPUKB4z1CgeM9QoILhnvH3/Ru07YgQAjNmzMC3336L1atXo02bNrLn27Rpg6SkJFlZ2Gw2Y+3atc6Q1KdPH+h0Otk5OTk52L17t8cgFczYbIKIiIiIKPg1aEXqvvvuw2effYb//e9/iIiIcK5pioqKcnbsmDVrFubNm4cOHTqgQ4cOmDdvHoxGI2666SbnudOnT8cDDzyAuLg4xMbG4sEHH0T37t2dXfwaEwYpIiIiIqLg16BBasGCBQCAESNGyI4vXLgQ06ZNAwA89NBDqKqqwr333ouioiL0798fK1ascO4hBQCvvPIKtFotrr/+elRVVWHUqFFYtGhRo9tDCuA+UkREREREjUGDBil/2keqVCrMmTMHc+bM8XhOSEgIXn/9dbz++uv1OLqG4VqRstuF27opIiIiIiJqWNyaOci4ZiaL3d4wAyEiIiIiIo8YpIKMa0XKauOmb0REREREwYZBKsi47n1ltTNIEREREREFGwapIOM6tc9q49Q+IiIiIqJgwyAVZNym9rEiRUREREQUdBikgoza5SfCIEVEREREFHwYpIKMe7MJTu0jIiIiIgo2DFJBxjVIWdi1j4iIiIgo6DBIBRmXHAUbp/YREREREQUdBqkg416R4tQ+IiIiIqJgwyAVZDTs2kdEREREFPQYpIKM69Q+NpsgIiIiIgo+DFJBhvtIEREREREFPwapIKN2q0gxSBERERERBRsGqSCjcklSFjun9hERERERBRsGqSDj2mxCCFakiIiIiIiCDYNUkHGd2seCFBERERFR8GGQCjIql4qUjRUpIiIiIqKgwyAVZFwrUpzaR0REREQUfBikgoxr+3N2PyciIiIiCj4MUkFGrXYNUkxSRERERETBhkEqyLhO7bOxJEVEREREFHQYpIKM69Q+FqSIiIiIiIIPg1SQcWt/ziRFRERERBR0GKSCjGv7c87sIyIiIiIKPgxSQUbjFqSYpIiIiIiIgg2DVJBxm9rHkhQRERERUdBhkAoynNpHRERERBT8GKSCDJtNEBEREREFPwapIOPe/pxBioiIiIgo2DBIBRkVN+QlIiIiIgp6DFJBRqPmGikiIiIiomDHIBVkXKf2cY0UEREREVHwYZAKMq5T+5ijiIiIiIiCD4NUkGFFioiIiIgo+DFIBRnX9uc2BikiIiIioqDDIBVk1GrX9ucNNBAiIiIiIvKIQSrIuBSkYGfbPiIiIiKioMMgFeSYo4iIiIiIgg+DVJDjGikiIiIiouDDIBXkBIMUEREREVHQYZAKMiq2PyciIiIiCnoMUkGOa6SIiIiIiIIPg1SQY9c+IiIiIqLgwyAV5Di1j4iIiIgo+DBIBTkWpIiIiIiIgg+DVJBx25CXFSkiIiIioqDDIBXkmKOIiIiIiIIPg1SQcc1NNs7tIyIiIiIKOgxSQY5T+4iIiIiIgg+DVJBjQYqIiIiIKPgwSAU5wYoUEREREVHQYZAKMq5d+7hGioiIiIgo+DBIBTnmKCIiIiKi4MMgFeQ4tY+IiIiIKPgwSAU5du0jIiIiIgo+DFJBjlP7iIiIiIiCD4NUkFG5dJuwsSJFRERERBR0GKSCHNdIEREREREFHwapIOOam+z2hhkHERERERF5xiAV5NhsgoiIiIgo+DBIBbnSagt+25/HjXmJiIiIiIIIg1SQCdFpZI83Hi3E3xdtwcq9uQ00IiIiIiIicsUgFWSu7JmMDpF2pMcaZccPnilvoBEREREREZErBqkgY9CqMaObHTNGtpUd59Q+IiIiIqLgwSAVpFQuG0pVmKwNNBIiIiIiInLFIBWk1C4b85YzSBERERERBQ0GqSCldqlIMUgREREREQUPBqkg5VqR4tQ+IiIiIqLgwSAVpFwrUsVVFghuzktEREREFBQYpIKUa5D680Qxnvh+dwONhoiIiIiIpBikgpTr1D4A+HTTiYs/ECIiIiIicsMgFaRUSkmKiIiIiIiCQoMGqXXr1uGKK65ASkoKVCoVvv/+e9nz06ZNg0qlkv0ZMGCA7ByTyYSZM2ciPj4eYWFhuPLKK3Hq1KmL+CkuDI2HHPXb/jzsyS65uIMhIiIiIiKZBg1SFRUV6NmzJ9544w2P54wfPx45OTnOP8uWLZM9P2vWLHz33Xf44osv8Pvvv6O8vByTJk2CzWa70MO/oFzXSDn8fdEWXP7a7xd5NEREREREJKVtyDefMGECJkyY4PUcg8GApKQkxedKSkrwwQcf4JNPPsHo0aMBAIsXL0ZaWhpWrVqFcePG1fuYLxaVhyBFREREREQNr0GDlD/WrFmDhIQEREdHY/jw4XjuueeQkJAAANi2bRssFgvGjh3rPD8lJQUZGRnIzMz0GKRMJhNMJpPzcWlpKQDAYrHAYrFcwE/jm+P97Tbv+0Y19DgpeDjuBd4T5C/eMxQo3jMUKN4zFKhgumf8HUNQB6kJEybgb3/7G9LT05GVlYUnn3wSl112GbZt2waDwYDc3Fzo9XrExMTIXpeYmIjc3FyP150/fz6eeeYZt+MrVqyA0Wis989RF39u3w5AAwDoGm3H3mL5LEzXKY5EK1eubOghUCPDe4YCxXuGAsV7hgIVDPdMZWWlX+cFdZC64YYbnF9nZGSgb9++SE9Px08//YTJkyd7fJ0QwuvUuEcffRSzZ892Pi4tLUVaWhrGjh2LyMjI+hl8HVksFqxcuRL9Lu0L7P0TAHBJx1bYu1neQGPixIkNMTwKQo57ZsyYMdDpdA09HGoEeM9QoHjPUKB4z1CggumeccxW8yWog5Sr5ORkpKen49ChQwCApKQkmM1mFBUVyapSeXl5GDRokMfrGAwGGAwGt+M6na7Bf3AOOl3tjyZEYUzBMk4KHsF0/1LjwHuGAsV7hgLFe4YCFQz3jL/v36j2kSooKMDJkyeRnJwMAOjTpw90Op2sBJiTk4Pdu3d7DVKNgbRrn17bqH5MRERERERNXoNWpMrLy3H48GHn46ysLOzYsQOxsbGIjY3FnDlzcO211yI5ORnHjh3DY489hvj4eFxzzTUAgKioKEyfPh0PPPAA4uLiEBsbiwcffBDdu3d3dvFrrKT78RoYpIiIiIiIgkqDBqmtW7di5MiRzseOdUtTp07FggULsGvXLnz88ccoLi5GcnIyRo4ciSVLliAiIsL5mldeeQVarRbXX389qqqqMGrUKCxatAgajeaif576JK1IGXTuQcrXOjAiIiIiIrpwGjRIjRgxAkIIj8//8ssvPq8REhKC119/Ha+//np9Dq3Byab2adyDlF0AGuYoIiIiIqIGwTljQUrlY2qfze45gBIRERER0YXFIBWkNJJFUgat+zRFu5dKHhERERERXVgMUkFK2mxCqWsfgxQRERERUcNhkApS0kYSSlP7OLOPiIiIiKjhMEgFKV9d+7hGioiIiIio4TBIBSnZ1D6FVu7euh0SEREREdGFxSAVpNRq7xUpFqSIiIiIiBoOg1SQkm4RpbSPFKf2ERERERE1HAapICXtyqfUte9CTO17d90R3PHRFlhs9nq/NhERERFRU8IgFaSkWUZxQ94LEKTmLduPVfvy8ONf2fV+bSIiIiKipoRBKkjZ7d4rUhdyZl+l2XbhLk5ERERE1AQwSAUpaXhSWiNl5xopIiIiIqIGo23oAZCy9Dgj7h7eDjFGnayDn4Od7c+JiIiIiBoMg1QQe2RCZwBAYYXZ7TkWpIiIiIiIGg6n9jUC7vUotj8nIiIiImpIDFKNgFrlHqUuRPtzIiIiIiLyD4NUI6BS+CldiPbnRERERETkHwapRkCpImW/gHvmqhQnExIRERERkQODVCOg0LSPXfuIiIiIiBoQg1QjoFiRYpAiIiIiImowDFKNgEKOYvtzIiIiIqIGxCDVCCitWWL7cyIiIiKihsMg1QgorZFi+3MiIiIioobDINUIKK2RYkWKiIiIiKjhMEg1AlwjRUREREQUXBikGgGVSuUWpji1j4iIiIio4TBINRKu0/tsDFJERERERA2GQaqRcJ3dx6l9REREREQNh0GqkXCtSNnrOUlxqiARERERkf8YpBoJ1zVS9noOPtLLKTW3ICIiIiKiWgxSjYTbGql6rkjVdzAjIiIiImrKGKQaCddNeet7jRRjFBERERGR/xikGgnXilR9r2liRYqIiIiIyH8MUo2E67ql+m5/zhxFREREROQ/BqlGQuXata++p/YxSBERERER+Y1BqpFwWyPFZhNERERERA2GQaqRcNtHqr6n9tXr1YiIiIiImjYGqUbCdWqfo/15frkJR86Wn/f1WZEiIiIiIvIfg1Qj4Tq1z5F7+s5dhVEvrcXp4qrzuj5zFBERERGR/xikGglfU/t2ny45r+tL26mrvJxHREREREQMUo2Ga0XKtf25xrU/eoDquwsgEREREVFTxiDVSCi1P7fa7M7HGtekFSBpRYqZioiIiIjIOwapRsK14GS3C5istUFKfZ5BSlqR4nopIiIiIiLvGKQaCaU1UrIgpZCjSqosfnf0ExCKXxMRERERkTsGqUbCbY2UXcBktckeu+r3XE1Hv8N5ZT6vL61Ccb0UEREREZF3DFKNhGtFSgig2lJbkbLY3NOPo2KVeaTA5/VlXQA5t4+IiIiIyCsGqUbCbY2UkFekpI0nXLmGMCWsSBERERER+Y9BqpFw7dpnEwImSUXK7CVIaf1oRCGtSAlWpIiIiIiIvGKQaiRcs5AQkDWbsCpM7XO+1o8gxYoUEREREZH/GKQaCdfpeTa7QLWldmqfxaUiZZekIX8qUrIlUnUcIxERERFRc8Eg1Ui4b8grb39usQscPVuOMS+vxXd/npJN9fNns15Z+3NO7SMiIiIi8opBqpFwzUJ2l/bnFqsdT/5vNw7lleNfS3YGHKS4IS8RERERkf8YpBoJ9w15IWs2YbXbUWWuDVZm2Wa9gTWbsDNJERERERF5xSDVSLhVpFyn9tkEtJraH6c0SPkTjLhGioiIiIjIfwxSjYVC+3PXZhPSphLSIGXzow2fYEWKiIiIiMhvDFKNhD/tz2UVKVuAQcrl2kRERERE5FmdgtTJkydx6tQp5+PNmzdj1qxZePfdd+ttYCSn1P5c1mzCS0XK6keQ4oa8RERERET+q1OQuummm/Dbb78BAHJzczFmzBhs3rwZjz32GJ599tl6HSDV8LVG6p11R3GmtNr5WPqc3Z8gJdmGijmKiIiIiMi7OgWp3bt3o1+/fgCAL7/8EhkZGcjMzMRnn32GRYsW1ef46By3faRcNuQFgD3Zpc6vA61ISfeR8uN0IiIiIqJmTVuXF1ksFhgMBgDAqlWrcOWVVwIAOnfujJycnPobHTm5V6Rq9o7yxGI7n659TFJERERERN7UqSLVrVs3vP3221i/fj1WrlyJ8ePHAwCys7MRFxdXrwOkGu77SAnZPlKuzC6NKHyRBilWpIiIiIiIvKtTkHrhhRfwzjvvYMSIEZgyZQp69uwJAFi6dKlzyh/VL9c9de1CoMpi9Xh+taQRhT8VKdk5XCRFRERERORVnab2jRgxAvn5+SgtLUVMTIzz+J133gmj0Vhvg6NabhUpO1Bptnk4Gyivrg1ZntZI7c8tRZhei7RYoyxI1aUitXx3Lgw6NUZ2Sgj8xUREREREjUydKlJVVVUwmUzOEHX8+HG8+uqrOHDgABIS+Iv0xWATAlVeglSZJEgp7SN1tsyE8a+ux9AXa7ovyvaRCnCNVGGFGXcv3oa/L9zi155VRERERESNXZ2C1FVXXYWPP/4YAFBcXIz+/fvjpZdewtVXX40FCxbU6wCphrR5BABYbXZUWbwEKZP3IHXkbLnzayGEbO+oQLNQSZXF63sRERERETU1dQpS27dvx9ChQwEAX3/9NRITE3H8+HF8/PHHeO211+p1gFTDtWHE9zuy8depEo/nl1XXhhulqX3SwGOzC5zPEinppEN/1mMRERERETV2dQpSlZWViIiIAACsWLECkydPhlqtxoABA3D8+PF6HSDV8GcvKCnp1D6lDXmlQcpiE7IqlDiPMMQgRURERETNQZ2CVPv27fH999/j5MmT+OWXXzB27FgAQF5eHiIjI+t1gFTDaq+d2tcnPcbLmTV8VqQkgcdss8sCUKBRSNoHg1P7iIiIiKg5qFOQeuqpp/Dggw+idevW6NevHwYOHAigpjrVq1eveh0g1bBYawPKi9f18Hm+rCKlUCWSThW02OzyfaQCDEMqyeQ+u+etrYiIiIiImow6tT+/7rrrMGTIEOTk5Dj3kAKAUaNG4Zprrqm3wVEtaUWqXYtwtI0Pw9H8Co/nl0uaTShtyGuS7DNVE6TqXpGSsnFqHxERERE1A3WqSAFAUlISevXqhezsbJw+fRoA0K9fP3Tu3LneBke1XKfn6TTef3Ty9ufuZSJp63SLVd7w/HzWOQUytW/V3jO4/u0NOFlYWef3IyIiIiJqCHUKUna7Hc8++yyioqKQnp6OVq1aITo6Gv/5z39g59yuC8K1qqTVqDycWaO40uz8WqlKVC1pne62RirAHCV/rf8vvuPjrdh8rBD//npnYG9IRERERNTA6jS17/HHH8cHH3yA559/HoMHD4YQAn/88QfmzJmD6upqPPfcc/U9zmbPdR8pXxWpokrveztJ96ByXSMVaNc+aZCqy9S+ogqL75OIiIiIiIJInSpSH330Ed5//33cc8896NGjB3r27Il7770X7733HhYtWuT3ddatW4crrrgCKSkpUKlU+P7772XPCyEwZ84cpKSkIDQ0FCNGjMCePXtk55hMJsycORPx8fEICwvDlVdeiVOnTtXlYwU11zCklwSp92/rG9BrAaDaUhvMLOfZtU8WpOrQtU/lvbhGRERERBR06hSkCgsLFddCde7cGYWFhX5fp6KiAj179sQbb7yh+PyLL76Il19+GW+88Qa2bNmCpKQkjBkzBmVlZc5zZs2ahe+++w5ffPEFfv/9d5SXl2PSpEmw2WyK12ysXCtS0ql9Gh/T/JTan0srUnmlJuSVmpyPA10jZZd1/AvopUREREREjVKdpvY5ws9rr70mO/7GG2+gRw/frbkdJkyYgAkTJig+J4TAq6++iscffxyTJ08GUFMJS0xMxGeffYa77roLJSUl+OCDD/DJJ59g9OjRAIDFixcjLS0Nq1atwrhx4+ry8YKSxW2NVG0G1vgo6Si1M5c2m7jj462y585njVRdpvapWJIiIiIiokamTkHqxRdfxOWXX45Vq1Zh4MCBUKlUyMzMxMmTJ7Fs2bJ6GVhWVhZyc3Odm/0CgMFgwPDhw5GZmYm77roL27Ztg8VikZ2TkpKCjIwMZGZmegxSJpMJJlNtBaa0tBQAYLFYYLE07Hodx/u7jkPa/txisUArzR7Ce/XNYrW7Xa/K7PlzWm3u53tjNlslXwf+PRRCNPj3vTHzdM8QecJ7hgLFe4YCxXuGAhVM94y/Y6hTkBo+fDgOHjyIN998E/v374cQApMnT8add96JOXPmYOjQoXW5rExubi4AIDExUXY8MTERx48fd56j1+sRExPjdo7j9Urmz5+PZ555xu34ihUrYDQaz3fo9WLlypWyx1abBji38e2yZcsQb1EB0ECvFtiyeRO8/ShPZWdj2TL5urHDx9TwNLPzxIkTWLbsmN9jPVkO5/uvWbsW+/3+Fta8pqy0tN4CeHPmes8Q+cJ7hgLFe4YCxXuGAhUM90xlpX9b89QpSAE1lR/X7nw7d+7ERx99hA8//LCul3XjOu1LCOFzKpivcx599FHMnj3b+bi0tBRpaWkYO3YsIiMjz2/A58lisWDlypUYM2YMdDqd8/j9G1Y4v544cSLG2QX678pFn/Ro5JZU4/U9WzxeMyExCRMnXiI79uNnO4D8PMXzW6alYeLEbn6PedfpEmDXJgDA4CFD0Skpwq/XOT5TZGQkJk4c6Pf7kZyne4bIE94zFCjeMxQo3jMUqGC6Zxyz1Xypc5C60JKSkgDUVJ2Sk5Odx/Py8pxVqqSkJJjNZhQVFcmqUnl5eRg0aJDHaxsMBhgMBrfjOp2uwX9wDt7GotPpoANwbd9WAICiKu9T++wCbtcy2TyvZVKpVAF9H9Sa2ttIpdEE/D1UqwN7P1IWTPcvNQ68ZyhQvGcoULxnKFDBcM/4+/516tp3MbRp0wZJSUmy8p7ZbMbatWudIalPnz7Q6XSyc3JycrB7926vQaqp0aq9/xh9bcjrKtAO5tJmE3Xp2sdeE0RERETU2DRoRaq8vByHDx92Ps7KysKOHTsQGxuLVq1aYdasWZg3bx46dOiADh06YN68eTAajbjpppsAAFFRUZg+fToeeOABxMXFITY2Fg8++CC6d+/u7OLXHPjIUR72kfIcpAJtvCfdwDfQ1ulERERERI1RQEHK0Ybck+Li4oDefOvWrRg5cqTzsWPd0tSpU7Fo0SI89NBDqKqqwr333ouioiL0798fK1asQERE7RqcV155BVqtFtdffz2qqqowatQoLFq0CBqNJqCxNGa+KlLrD+Xjh53ZuKJnivOYyeK5dCQCDEPSLa78aX++82Qx/jiS73ysAktSRERERNS4BBSkoqKifD5/2223+X29ESNGeP2lXaVSYc6cOZgzZ47Hc0JCQvD666/j9ddf9/t9mxqNHxM0Z37+J376KwfX9mmJMV0TvVaOAq0pyaf2CZSbrFi9Pw+XdU5AuMH9FrvqzT8CfAciIiIiouASUJBauHDhhRoH+WDUa1BptiEx0r1JhsbX3L5zlu/JxfI9uTj2/OVeK0eBTs+TbchrF/jXkh1YufcMxnVLxDu39vX5eq6RIiIiIqLGJmibTZDcV3cPxNiuifj0jv5uz2nVgScRu5eOEoGvkar92iYEVu49AwD4Zc8Z5/ENRwpw47sbcDivzO31zFFERERE1NgEbftzkuuWEoV3b1Ou7qjrEqS8hCVPFan1h84iOlSP7i2jPJ7vKYRNeW8jAOAfH28LbKBEREREREGIQaoJCLQiJYRQ7OTnfF7h2MnCStz6wWYAwLHnL5c9J72Wt+sCQHZxlftBzu0jIiIiokaGU/uaAI2HIBWiU/7xVphtXpt8KD13srDSy/m1X/vq2icEEBEiz++MUURERETU2DBINQEaDxWdiBDlXZmLKsxeA4/SU/42p/C29spxrt6lzSALUkRERETU2DBINQEajacgpTxzs6TKItv7yZXSGinplD3XipU0O/ma2scNe4mIiIioKWCQagI8rZHyVJH6etspH1P73I9JA5JrVpJVpHzkJLtgBYqIiIiIGj8GqSZA7SGZhOk1iscXZR5DQYXZ4/UcYehsmQnfbDuFaotNFpCsdnk5yy4LWf5UnFReHhERERERBT927WsCPFWk6l75qQlD1y7IxInCSmTlVyAjtbbluUuOCmhqn9K4VCxREREREVEjw4pUE+Cpa19dObLQiXOd+tYczJNVmlwbT8in9vkRpHw8JiIiIiIKdgxSTYCnis6ANnGyxx0SwtEq1ujzeq7rp2KMevleUTbPQcqfihQRERERUWPHINWEtY4Pw6rZw52PNWoVdB46/Em5ZqEYo95rRUr60J8cxaxFRERERI0dg1QTFmbQoF2LMOdjnUYNncb3j1xAXlmKDdPDIqlCuTabkHX08yMluVa8LsYSqR92ZmPO0j1+jY+IiIiIyBc2m2jCDFqNbNqfVqOCSuVHkBIChZKufpGhOpitteHJvdmE52qVEtdzVBdhldTMz/8EAPRtHYNJPVIu+PsRERERUdPGINWEuXbz06nVUKv8qRgBBRUm2TGLZAdfb1P7/Fkj5VYVuojdJs6UmnyfRERERETkA4NUE6bTyqtPWo0KGuHPGimB/LLaipTdLuRBykuzCX+69vm11dQFYnMtpxERERER1QHXSDVhRpcNeTVqlVu4UiIEsOt0ifOxTQiYrJ4rUtICkz9rkNyn9nm2OasQp4oqfV7TX1aukSIiIiKiesCKVBN0z4h2OFtmQqfECNlxnUYNf7acstrteG/9Uedjt4qUa7MJ2Rop39f3p2oFAHuzS3H9OxsAAMeev9yv1/jiWk0jIiIiIqoLBqkm6OHxnRWPa9Qqt3VTSkqqLLJmEza7kDWbWJR5DKnRRtwzoh0AeRc+k9Xm8/puS6QUhpRfbsKcpXt8XitQrEgRERERUX1gkGpiIkI8/0h1GhW0at9T+ywuVRubkFekFm88AQCY3DsViZEhsul8Ly4/4PP6rtP/lLr23fL+JuzPLZOMye5X63ZfuGEwEREREdUHrpFqYhIjQ9yO3TOiHUJ1Gswe0wl6P9ZISatPgGNqn3sAcZwXaDbxZ2qfNEQBNVWy+sCKFBERERHVB1akmpgkhSD18PjO+NfojtBr/duQ12xzXwOltLZIc26aoKdg5GkWoT9T+1wVV5oRH27wfaIP7NpHRERERPWBFakmRqkiBcBZidJrfKcWi2uQsrsfqzlek4g8BSmVPwnJT8WVrEgRERERUfBgkGoihnVsAQD4++DWXs/zpyJlUZja5zrdDwD25ZTi131nPE7t8zdG+ZO3iuopSHGNFBERERHVB07tayI+mNoXhRVmjxUpB3/2kVKa2qdUkbrn0+2w2QWm9EtTvI6/BSmlZhOuiivNPs/xBytSRERERFQfWJFqInQatc8QBQB6fypSLuuhXPeRcnBUd3JLqhWv409A8le9Te1T+BxERERERIFikGpm/Ona58omBEwKU/scKkwe9o6S5Chv21f5N7Wv7hUp6T5XrEgRERERUX1gkGpmdH40m3Bl81CRcigzWRWPS99JfZ6NJ0qr616RkmYn1z2siIiIiIjqgkGqmanLprZ2obyPlEOFpyAlq0idX5CyWOsegOysSBERERFRPWOQambqEqSsNuWufQ4eg5SkJuUtR/nTJt21AUYgpEGKXfuIiIiIqD4wSDUzdVkjZffQtc+h/DwrUsLDPlRS5xWkJC9lRYqIiIiI6gODVDPjT9c+Vza78BpkPDWicESn/646hCqLh4YUAPzIUbK9rXadKsH0RVtw8EyZ7xeCFSkiIiIiqn/cR6qZqcvUPpuoWwBRqVSottjwyqqDXs+zB1iRuvLN3yEEcCivHOseGunztTaukSIiIiKiesaKVDNTl659druA1UuzCU9U8K/a5FdFShKkHOdnF1f5NQ4hKZjZ7NxHioiIiIjOH4NUM6OTrJHSetvcScJmF7DWJYCo5NUgT/ypSCl17QvVafwahnQM3roPEhERERH5i0GqmTFIpvZp/axO2UTdK1I2P17nT0XKpLBGK1TvX5CStT8/j6YVREREREQODFLNjLQi5Wu9lKNgZfexIa8nKpWqHitS5xGk7KxIEREREVH9YpBqZqThyVcHP4O2JqjYhKhjswn4NSXQ9cpK7dCVugb6O7VPOvS6BEIiIiIiIlcMUs2MtNmEr4qUQVfzvN0uYKlDkLLZBfxZWiWtSL299gj6zl3ldo5SADLWYWqfI5BlHs7HrR9swvGCCr+uQUREREQkxSDVzEirUDqt9zVSjnNr1kgFXskRwt9mE7VfP//zfhRUmN3OsVjt2JtdivnL9jmPGfX+de+XVtPM56YI3vT+Jqw/lI9/frHDr2sQEREREUlxH6lmRi9dI6X2ryJltQnUZfslm1342WzCv32kJr62XnYsxM+pfcLL1L7cEv9aqBMRERERSbEi1cxIp/P5nNp3bo2U0vokf9iFqLdmE2aFZhOOoOeLdAyu1/GnYyARERERkSsGqWZGF0D7c8O56pXJch5Byp9mE36EGaUw508lyzEOB9c27sxRRERERFQXDFLNjHSNlK8c4ghSda1I2ewC/rzUn2mDSm3LPe1tVWGyyq8vbX9ut8sCGCtSRERERFQXDFLNjLTBhK+W5o6pfSaLza9rd0qMkD22C9/vAfhXWVK6jtKx7/48hW5P/4KPMo/JxuFQbbFj0POrpe/u872JiIiIiFwxSDUz0oqUr/VLjjVIJoX1SUqijDq3Y/7sI+XPGiklVoUg9a8lOwEATy/d4zzmGrhySqr9fg8hBG5ftAX3fbq9TmMkIiIioqaJXfuaGY26tiJl91mRCmxqn9IGv0pNIlzVpSMg4F+1q+b6ns/zleGyS6qxen8eAOBFkxVhBv4nQ0RERESsSDU7KlVtkFKq6Eg5pvb5WzDSKTSv8CeE+ds0wlW9BCkfr5WOra6VMyIiIiJqehikmjGlIGLU1+7NZNAGdntoFSpSnhpCSNU1nyiNX63QiNBb3vIV4mTB04/PQkRERETNA4NUM6a0fiklOtT5tT7AIKU0tc91A1wldV8j5X5t6dTFZ3/Y6/P6gVSk/PksRERERNQ8MEg1Y0q5IDkqxPm1Y2qfv5Sm9vkXpAJ6GyflilTtGD78IwtCCK9rwXxlOGkVqq5t4ImIiIio6WGQasaUKjWpkoqUo2ufv3QKFSl/Ov7VtSKl1HVQ4zK3z2yzn9fUPuk6Mk7tIyIiIiIHBqlmzKpQYZFO7auPNVJKG+m6qusaKatNQAiBZ37Ygznn2p1rVPIgVW2xe21K4frMuoNnsXx3jvOx9LWc2kdEREREDuzl3Iwp5Yu+rWOcXytVmLxRmtqnFNZcCSHw54ki7D5dEtD72ewCxwoqsfCPYwCAf4/rBI3LGExWm/eqk+QpIQTuWbwN1VY7tj8Zj6hQnSw8+RMKiYiIiKh5YJBqxpSaNfRrHev8urTKEtD1lIKXP1UcmxC45q3MgN4LqAlSe7NLnY/NVrtbRcpksXvdeFj6jNlmR4XZBgAoqjAjKlTHihQRERERKeLUvmZMacqbVqPGE5d3QeekCEzqkRLQ9ZSC1N6cUoUz5c6UmgJ6HwerXWBvTm0Vy2yzQ612ndpn83uNlLTiVG6yOt+j9nkGKSIiIiKqwSDVjHlaO3TH0LZYPmsYkqNDZMcTIw2YP7k7/jmqg+Lr9ApT+z7ffPL8B+qBUkXKdR+paovde9c+yddmSWOMsmqr8z0cHEHrzxNF+PD3LFhtdmQXV53HJyAiIiKixopT+5oxX23HXafJadVqTOnXCl9urQ1HKlVtswilZhMXks0uUCyZfmi22d3WMZmsNu/7SEmekgapCkdFSrZGquZrxzTEF3/Zj2qLHR9O64vLOifW/YP4wW4XMNvsCNEF1pKeiIiIiC4MVqTII9dpco4goZUc75oc6fw60OYU/uqUGKF43GoXqDq3pgmoCUImi012ju+ufcpT95Sm9rmuKau21Dz+v18O+voI5+2Gdzcg4+lfUBLgujUiIiIiujAYpMjp7Vt6yx677snkCCTS41MHtnZ+XVZd/7/k//HIZUiNCVV8zma3o0oSnCw2u9u+Vb7XSNV+LX1tmcl9ap/Zqnyhs+V1W+MViC3HimC1C6w7ePaCvxcRERER+cYgRQCAgW3jMD4jWXbMdWqfo2IjDRfDOrZwfh1t1NX7uBIiDNB7qHTZ7AKVkopUldkmqyABQLWP9uee1kiVn1sjZVGY2ucq/yIEKYe6bl5MRERERPWLQYoAyKe4Oahd7g5HgDpeUOk8lhhpwA8zhuDRCZ0xsbs8iHmjtOeUEo1KBZ2HjYFtdoFqSZByTMeT8tX+XEoalCoUKlJK7eKBum8oXBcMUkRERETBgUGKPHKrSJ0LFVf0TIFGrcLYrolQqVTo3jIKdw1vF1AjhEHt4vHDjCE+z1OrVR5Dl8UuUCmZ2ufotAcAo7vUNH+otnqf2ifNj2aXNVLbTxThnk+3176fh6l9F5OHLEdEREREFxm79hEA5aqKpzVS7RPCsf2JMYgIkd8+rsHLG41a5XMqoOPtDR4qUmaX9VCONVo6jQpGfU2oq7bYEab3r9mEa/vzOz7aKjvXYrfLuvi5jkXvYZz1yd/qGhERERFdWKxIEQAoTOwDVCrlIAUAUUadW1c/jZ/T9QC47fekxBHk/O0GWHquIhWi1SBEV/OammYTfrY/l1WkLCisMMvOtVjdm1k4FFeZFY/XN297YrnKLq7Csz/sxfGCigs4IiIiIqLmiUGqGYoKrakE+btOyV+BVKTswr29uiu1KrAg5VgjZdCpndMMTVbv7c+tdoE3Vh8C4NJsQmG91VtrjuCnXTmK15G2Ya9v0vAUQI7CXZ9sw4d/ZGHKuxsvwKiIiIiImjcGqWbo838MwNAO8fj67kG1B+thxpjrVEBvKs1Wn1Upx/WkU+biwvT4z1XdFM93TO0zaDXO6YAmi81nM4j/W1GzD5R8Hyn3YJRXZsJDX/+leI0qy4ULUtJOhIFM7dt1ugQAkF1SXe9jIiIiImruGKSaoa4pkfhken/0TIt2HmsTH3be1w0kSFWZbc6KkydKFamx3ZIwuXdLxfNPFlYBAGLCdM6KVLXF5nf4kLc/D2xPrMoLWZGSjN9bK3ciIiIiunjYbKKZ+/rugfhm+2k8Mr7zeV8rkKl9FWYbpKerVJ7biEubTYTqNB4D24HcMgBA2/hwSZCy+9Uy3GKz+5za582FnNonq0gFMrePiIiIiC4YVqSaub6tYzF/cndEeeigt/3JMX5fS7rmqW96jNvzT1zexfl1ldkGFWrPD9O7Z3pHaJCu5QrRqaH1EKRyS2umsLWJD6ud2me1+dWgoaTKIp/aVx1YkLqQFSlbHddIEREREdGFwyBFXsWG6fHZHf3RMiYUn0zv5/fr7rusPX6cWbtP1PQhbXDH0LbOx65rpBztyqVqg5R/FSmHti3CYJBVpHyPt6TKIuvIVxFgMKo0Bxa8AiENUluPFeL1Xw95bMNORERERBcHp/aRT4Pax+P3hy8L6DVatQppMUbnY9fpdRUua6SUgpSjHbm02USITgOVSgWNWuVxmlvb+HAcyquZ5lfpo/25Q3GlRdb+PFAXcmqf9HP+vDsXP+/ORUyYHrcMSL9g70lERERE3gV1RWrOnDlQqVSyP0lJSc7nhRCYM2cOUlJSEBoaihEjRmDPnj0NOGJybLLbo2U0dNraoOQ6vc5stcuClGNNkxJpRcqxP5S39VhRoToYz00VrDRZ/VpXVFplgcVa93lzF7Jrn9L4j5wtv2DvR0RERES+BXWQAoBu3bohJyfH+WfXrl3O51588UW8/PLLeOONN7BlyxYkJSVhzJgxKCsra8ARN28bHx2FnU+NRVSoDnpJAFLqnKeS3H2hChUpB4NLRQqA1+pRiE7trHBVmH23PwdqNtQ12+oehirNNnyy8Tg2HCnwet6v+87g7bVHcLbM5Pe1Fb93qN89wIiIiIgoMEE/tU+r1cqqUA5CCLz66qt4/PHHMXnyZADARx99hMTERHz22We46667LvZQCTVBxxF2pGuZlIpC0ihg1Gug16plnfMc5BUp98DVJj4MWfkVzscGrQZhhprzKs1Wv9qf780u9XmON+sPncXGo4UAgGPPX654jsVmxz8+3gq7AP44nI9Ppvf369o2m0KQ8iNHeeuESERERETnJ+iD1KFDh5CSkgKDwYD+/ftj3rx5aNu2LbKyspCbm4uxY8c6zzUYDBg+fDgyMzO9BimTyQSTqbYiUFpa80u0xWKBxRLY/kH1zfH+DT2O+ma12tw+k81a26DBoFFDr3EPUhaLBWpRe0ynFrLrtIwOweRLkvHSqsPOYxrYoD+XvY4XVGLHiSKf43tvfRYGtY0N6DNJHTpTO9XObDZDpZB0yqqtzkB5uqjK759xtdnsdsxut7vdK67XU6tUzhDZ1O4nOj9N9e8ZunB4z1CgeM9QoILpnvF3DEEdpPr374+PP/4YHTt2xJkzZzB37lwMGjQIe/bsQW5uLgAgMTFR9prExEQcP37c63Xnz5+PZ555xu34ihUrYDQaFV5x8a1cubKhh1BPam6x4ydOYtmy4xiTqsbK02r0a2HHyhUrnM8X558BbCrAZcrasmXLsK9YBaCmwvTX9m0wHRXO12mtVTh86IDzeQBYteIXFJhq33v5njMAgH4t7NCogA15yjNaM89VlOqiymRyjv1/P/4MpZmKZZbaMZWWl2PZsmV+XTu3svZ1DseysrBs2RFklQHxIUCEzv2eEULjHJO/70XNS9P5e4YuFt4zFCjeMxSoYLhnKisr/TovqIPUhAkTnF93794dAwcORLt27fDRRx9hwIABAOD2L/9CCMVqgNSjjz6K2bNnOx+XlpYiLS0NY8eORWRkZD1+gsBZLBasXLkSY8aMgU6nvLdTY3L/hhUAgJTUVEyc2B1jbXbsyi5Ft+RICCHw782/AgDatU5DeGk11h2SrzGaOHEiYo8W4u19WwEAwwYPQJ/0GOd1O7ZKRM82sfjf8f0Aajr8XX75RBSUm/CfP9fKrtUmvRUGtInBhq92ob7ZoAFQUznrP+wyJEeFuJ2TXVwFbF0PAFDrQjBx4nC/rn0gtwzYuUF2rG3bNojuEI9XF21DqE6D5/ua3O6ZBzevhP3ctMCJEyfW5WNRE9XU/p6hC4/3DAWK9wwFKpjuGcdsNV+COki5CgsLQ/fu3XHo0CFcffXVAIDc3FwkJyc7z8nLy3OrUrkyGAwwGAxux3U6XYP/4ByCaSz1QUB17jMB/dq2AADZNL4wgw7/97fOeGnFQSzZetJ5XKfTIdRQ+30IDzXIvi9JUaGy50O0auh0OkSFuVeddFo19Arf04zUSOw+fX5rpGR7UFmE4s/OhtrppFVmm98/X5XGvbyl1Wiw9lBNBc3RMdD1nqlpSCGczxG5amp/z9CFx3uGAsV7hgIVDPeMv+8f9F37pEwmE/bt24fk5GS0adMGSUlJsvKf2WzG2rVrMWjQoAYcJSlR6Jcga5gQotMgITIEL1zXA21bhMnOc91HSio1OlTWjMKxEa+jTbqUWqWCRuGOH9Amzuf4x3dLwrCOLXyeB9Rs7qtEvuGvFcLPThCK7dtV7ntzKZ0T7Fzb4hMRERE1FkEdpB588EGsXbsWWVlZ2LRpE6677jqUlpZi6tSpUKlUmDVrFubNm4fvvvsOu3fvxrRp02A0GnHTTTc19NDJhdIvzJ425A11CUvSoORok/6v0R3Ru1U0bh2Y7hK0ar5Wmt5ZE6Tcb/mESAPW/ntE7eMI92plWmwoQhXCmZLiSguOni3Ha78eQll1baiSVuDsQh6svFEKUip43pDYQR3kQepkYSX6PrcKL6840NBDISIiIgpYUE/tO3XqFKZMmYL8/Hy0aNECAwYMwMaNG5Geng4AeOihh1BVVYV7770XRUVF6N+/P1asWIGIiIgGHjm5UvqlX/qLvjRIGfWuQUqyce+50HT/6A64f3SHmvMlwcug9bwflaeKlEatRnpcGL68ayC+3HoSY7om4q5PtrmMH9AqvVhBSZUZ415dB4tN4ExpNZ67pjsA9+BUabZ53Yi49r2V25/7ause7HtN7TpdgsIKM9YeysfssZ0aejhEREREAQnqIPXFF194fV6lUmHOnDmYM2fOxRkQ1ZniprKSqpE0ULiGC+neu0rBIyKk9jaWbt7rSq2SV8EctOcSXb82sejXJlZxap5dCOj8LPEUV1pgOTeXcfuJYudxk1W+4W+l2YrYML3s2J8nivDC8v144vKuyEiNAuCpIuV7Wpw/e001JMfnUto7jIiIiCjYBfXUPmo6fP3SL53O5zq1T0opSIVLgpS3Co9GrYJWYWqf2iUgRYXqEG2ULzK02YViRUpaLXMolgQx6bRDk8W9IuXqhnc2YuPRQkx5b6PsvV2pVB7WTknP8fpsw3OM3zVgEhERETUGDFJ0Ufiahiadznddn5YAgI6J4QCADgnh6N8mFpN6JEOjUBWKDKkNPd4qUiqVCgo5ylmRklr9wAismj3M+dguhGJoig93X08lrWgZJOFLaWqfa8MJ87nyW1l17WbFnr53vr6nStW3YOIMUhZWpIiIiKjxCeqpfdT4jemaiJV7z2D6kDZezwuVBKkxXRPxw4whaHOue59arcKSuwZ6fG24ofY2Vgpatc8BGoVwofSa2DC9bNqdXQjFalZkiA4F5WZnAAKAckkIclSkckqqcKa0WvbalXtzMfXDzZh7dQau6JnicdxWhcqT1S58d7yTfCybXXj93jQE59Q+G4MUERERNT4MUnRBvX1LH+SXm5AY6b5BrZQ0tKhUKnRvGeX3e0in9lkkv5Q/P7k7Hvm2dvPdmmYTntdIeWOzC4ToFF6rUSEyVIf88to9oipMtUHKoFWjpNKCgfNXu732zd+OAABmfv6n1yBlU+gdb7UJxYAlJR2txWaHRu27scXFZHVWpDi1j4iIiBofTu2jC0qjVnkNUU9c3gW3D26D7qn+BydX0vboFknouLFfK7xyQ0/n405JEYpByt9KjU5hjZRWo3ZbT1XmUpE6VlDh1/WrFNZMAcpT+Gx2IdtHSmmWn3Tt14Ws+lSarVj4RxZOFVUG9DrH52JFioiIiBojBilqUHcMbYunruiquO9TXVhcfinvkhwJAEiMNGBChvIaK29B6sGxHZEYacD9ozsqVq50ahWiQ+VBKq+sdgqfXqv2q3veyysPostTyxWfU2oqsSjzGP46VeJ87GuWn1VpR+R68uLyA3jmh72Y9PrvAb3Odu5nZbLa/d6cmIiIiChYcGofNSmurbQ7J0Vi2T+HIi02FBq1ykP7c8//njDjsg64b2R7qFQqxa59Wo1KtkYLAHIla6HUKpXHSpPUa78e8vicp+58p4qqas9ROEW6hso1YNan9YfOAqhp+x4Ix5iFqJnmp9TMg4iIiChYsSJFTYrSNLGuKZGIONfZry5T+xzVMqV9pHQaNaJC5XtBVUu60JmtdlSe5xogX23OAeUgJV1D5QiYK/bkov+8Vcg8kn9eY5LyVU2sUuhOCAA2e+33ybWjIREREVGwY5CiJsVX5UVpel7vVtF+XVujUDHRqlWY2D3J42tMVjuqXSpSUwem+/V+DvURpBxf3/nJNpwpNeGW9zcFNIa6mvvjXnR7ejn+3y8HvI6PDSeIiIiosWGQoibFYvWxt5IkSIXo1Nj2xGjEKewFpUSnMAVwT3YpRnVJxKbHRuHzfwxwH4/NjiqXkBBl1Hvt0ufw5m+HcaKgss5ByuZlap8fl8TZMhOyi6t8nuepHlVSacH7v2fBLoA/DrtXwKRTD9lwgoiIiBobBilqEm7q3woAMHtsR6/nSfeRCtNr/Q5RQM16KFeOjoSJkSHopVDZMlvdg5RBq0ZihO/3/X+/HMDtH23xufEu4B6khBCyIOW6dswXIQQufW4VBj2/GuWSdu6BMFlrP3eZwjXkFSkGKSIiImpc2GyCmoS5V2Xg7mHt0CrO6PU86XoodYAb1EqbTfw4cwg+23wCN16a5jxm0KqhUavkAcZmd2s2YbML2d5X3hzOK/e5XxTgXmFyfY0/15CSrlk6XVSFTkkRHs/1tETKInnPogqz2/Ou3yciIiKixoRBipoEtVrlM0QBLkEqwCZx0mpWSnQo5l3TXfa8SqVCmF6DUsk+UmarHdUuFanCCjNaxoT6/b72Okztc2137pjaF6rTuFXIlEgrRL7at6s8TO6zSsJRcZUFNruQff9trEgRERFRI8apfdSsSH+R1wS4d5V0ip1Bq/yfjqM7oIPS1L78chPGdE306z0jQrR+VZPcgpRdHkwcQSpM0qrd295N1ZJpefY67vEk3RxZCKC4Ul6Vklek2GyCiIiIGhcGKWpWpPtIBboJsPAjSIUZNLLHFpsdVWZ5qLnqklSkx4Vh/UMjEaqTn++qRbhB1ibcE9es5dqgwmSp2fQ2RFc77kov+1tJq2i+qkWevo2uYyis8BykWJEiIiKixoZT+6hZkVakAsxRsl/8lTbnBQCjXv6f1NH8CrSJrwAA3D28Ha7omYyuyZEAgLRYI5KiQpCVX+HxPU1WO4r82OjWdYmRxaVEVWG24ub3N8k28S2sMKPSbIOAQEJEiOx86V5Ydd3jybVToGuQkjWb4D5SRERE1MiwIkXNijRIBTpjzZ825NKKj8Ov+/MAAPHhenRLiZJVwlwrWK5OF1dhwZojvsfmoyJVVm1F5pEC2bEzpdW4/LX16PfcryhxCWuyipS1btPuXKckeq1IMUgRERFRI8MgRc2KdEqer817XfmzVsjbVL0QhefC9PVTFLYJeXlt+e4c2WPXEAPUhLS8MhMA4KttJ53HSyotKK6qDVazvtiB08VVsNuF2zonwPMUSdcpiQWuQUpIgxTXSBEREVHjwiBFzYo0SFUEuD+SP7lLKSw5KIWscINykPrq7oE+3+u+ke1qxybJeHa7wJwf9srOLSh3D0B5pSbn16vPVc3Kqi3o+ewKTP1wc+1rK8wY98o6PP79Llzy7ErsPFnsc2yA+/TCsmr599smeT7Qfa6IiIiIGhqDFDUr0upJhZdmC0r8qUh5DVJ6hYqUhyDVLSXS53sNahePjNSa8xyZJLu4CpuyCt3OLawwuR3LK6t2fu1Yh7U3u1TxvcpNVny+uaZq9dTSPR7HJJ2u59qCvaxaPn1QXpFikCIiIqLGhUGKyE+Te6cCAEZ2auHxHKU1Ug46hQYVShvzqlQ11Sutj42uQnRqaNU11/wtW4Wfd+fi8tfWY8p7G93OPVZQ6XbMMa0PAErPTeWz+REWd58ukY9X8rW0smRxmdrnVpGysyJFREREjRe79hH5KTkqFHufHed1HZRB6/k5pVikNLVPr1FDpVIhVK+RhY/uqVE4WVSJ4nPVI4NWA52m5qqHStX455K/PL73DoXpeNKpfSXngpQfndZhswvY7QLqc0FPukTKbLMjFDXfA5uPihS79hEREVFjxooUUQCMeq3X/aeUpvb1bxOLGy9Nw7CO7pUspWYT+nPruFyfS4oKweLp/SXvVVuRqgvp1L5ykxUWm92vihQAlJtrA570JY4GHjklVc5wJn0PKbudzSaIiIio8WJFipqdUJ0GVZYL84u70tS+m/q3wlWXpCqer9T+3DGlz+jyXFm1RTY90KDVQKtxD3XTBrVGu4RwPPn9bq9jPXJWvn9VaZUFFj8rQ+XVVkSG6AAAVkkZy2y141RRJYa88Jvba0pdpva5vs5mFyitsiAmTI8vt5xEXlk1ZlzWwa/xEBEREV1sDFLU7ISHaC9gkHIPRo7AoSRCYY2Uo1DjWpEqq7bK9sEy6NSyxw4906JwTa+WGNc1EduOF+GeT7f7Nfb1h/Ixa8kOv86VdjyUduez2OzY4LJflXT8UtIuiCarHTM+246Ve89g+ayheOibmmmK4zOS0T4h3K8xEREREV1MnNpHzY6nluP1IUQr/0+qVawRA9vFeTxfqWufowmD0aXLX83UuNrQYtBqFFu4J0WGAgASIkMQE6b3e+z+higAKJO8r7RRhNlqh+vkwGhjTZB069onqUhVW2z4eXcurHaBJVtq97SqCrCzIhEREdHFwiBFzc4FDVKSitTHt/fDbw+O8NoSXSlIOab7tYkPkx1vFWuUNWgI0alRWuUepOLDa8PThfqs17+9AdnFVQDkGxubbXa4LrOKMdaMx3WNlPSz7M8tc36tVehuSERERBRs+BsLNTsXK0gZtMpT77yNJTkqBJN7twQA9E6PcR6/tHUMXri2B/SSkKHXqN0aOgBAXLjB+bXaS2OM82G1C9zx0Vbn1w4Wm3Dbb6u2ImWFOPfcJxuPY/2hfOc5244XOb/OORfQAKCaTSiIiIgoSHGNFDU7V12Sgg1HC5AaHVrv15Y2mzB4qUQ5SNdB9W4VjW/vHSx77PD2LX2cAenOYW0RY9RDpVIpBqno0No1WelxRtlzeo0a8yZ3x4Nf7fT9YXzYm1Ozea/FZWpftcv6s9hzFSmbXaDKYoNRr/XaCONkkSRIXaC1bERERETni0GKmp3r+6YhMSoE3VOj6v3a0vCk92OKmrTZhOvaonYtwjG6SyKsdjtiJWudHpvYxfm1UtMMtaQKFmbQYtXsYRj98joAwMjOLRAXwLopX0oqLTBLpva9t/4ouqVEys6JCNFCo1bBZhcoq7bCqNDyXepEYe3mwVwjRURERMGKQYqaHbVahZGdEi7ItUMkG/Lqtb6DVJxkPZNrdz+VSoX3p/Y97zG1jKmtStns7lWq87EwM0u2me7KvWfcPodOo0a4QYuSKgvKqq1IjHS9itzZstqNgu/8ZBu+vGsg+rWJrbcxExEREdUHrpEiqkeyqX1+BCmjXovP/tEfA9vG4ab+rQJ+v2vPrafyRjoOm92Oti3C8ekd/b28wn+vrjrkdiynpEr2WKtROdeCuXbu88f172xwO2a3C+w6VSJrdFFXv+3Pw75z0xSJiIiI/MWKFFE9cm024Y9B7eIxqF18nd7vuWsyMDEjAS/+bysOlCi/n0rScMLRF2Jw+3j8v+t64KutpzCkQzxeXnmwTu+vJNNlHymtWu2cwjj3p30w1UMDiTd/O4yXVh7ETf1bYd413d2et9kF7l68DXqtGm9M6SX7HkgdyC3D3xdtAQAce/7y8x4XERERNR+sSBHVI51GsmGu1nezifMVotNgWId43Nzejut6p+LHmUO8ni/tqPe3vmn48u6Bbm3Wpa7omYLr+viuenmj1aic0/22HS/C7tOBV39OFVXKHv/315pK2GebTiiev2rfGazcewY//ZWj2CLe4VBebdt1u911lRoRERGRZwxSRPVIWvnwZ41UfYnSA/Ov6YYMHw00bAphwdGeXMk9w9uhZ1r0eY1Nq1bJmmrUxdGzFbLHSvtvSf1vx2nn16VephOqUPvzKlbogBiIXadKsHjjcWeLdyIiImraGKSI6lF8WO0eThczSPlLKUhFhXoOUhEhWtkUxZ4to5AUGaJ47qB2cYrHtRr1eQep/HKT7LGvvcBOS1qol1V7rkhJ12wVVpg8nuePK974HU98vxsr9p45r+sQERFR4xB8v+kRNWJRRh2+vnsgls4Y7HMz3obgulkuEFiQ6pYahY2PjcJtA9PdzvUUbnRqFcL9DFKevmX55SYUlJtw47sb8M22UwgzeJ82WWaqDU/eGlxIq1D55Wbn1wdyy3DHR1uxJ7vEr3FLHc4rD/g1RERE1Piw2QRRPevbOnhbdfuqSI3qnIBf9+c5H4cZtLIGGmnnWqlLK0x90mPwtz4tsflYoeJ71lSkPIc1h3CDFjFhOpwsrHJ77u21RzFv2X4AwMajhegl2azYZhdQq4Dlu3PRNSUS6XFhqJAFKc8VqaLK2vBUIAlSt3ywCWfLTNh5qhhbHh/tc+zS6Xz+7B9GREREjR//j0/UDPQ+FzxuuDTN7TlpyLllYDrGdE10PtZp1LKKVKvYmiAVbqh9zdyrM3Bjv1aIkFSkpA0qNH6ukYoK1aFFuEHxucIKs+yxUV8b7oorzVi6Mxv3fLodN7yzEQBQLglP5SbPQaq4Qnlqn2MvK+meVt5UW2rbsBt0/GuViIioOWBFiqgZ+GR6f+zPLXMGKinpFMQ2cWFuezNJuw86NvOVTq1zbCpskFSupJ0AdRoVQvW+/6ppEWHwezqkxVZbASqoMGPhH8cAALml1bDbBSrMtS3WvU3tk1akpFP7AlUimSLoqdU6ERERNS0MUkTNQJhBiz7pMR6f/2XWMOSXm9A6PgxmqzxISaetpZ2rSFklQSbWqHc71jquNkhp1WpZtcqTGKPO6zQ8KZOlNig5puA5VJjl1yj1cs3iytoAVKDQbELrZ7ArrqoNYdKxERERUdPFIEVE6JQUgU6IAAC3ICXtPuhYT2WSnKM9tybIaq895qhSATUVKelUPE+iQnWyKXLeSCtAN7+/Sfac61Q+f9dIFVVa8L8dp2Vr3EL9GDcAlEgCWZWZQYqIiKg5YJAiIhmzy9S+Pukx+Odl7dE5OdJ5rGea+35V0ul2sWG1QUqjVqNrSiS0ahWsXja9jQrV4Y6hbXHd25k+A9WxgkqPzw178TfZY09T+2x2gdPFtY0tfvorBz/9lSMLfUa9BmfLTIgP13udsicNdi+tPIikqBD8ra/7ejRvLDY7DuSWoWtyJNRB2PGRiIiI5Lgqmohk0iXT8oCaNT+zx3bCxO7JzmOD2sXjnVv74LcHRziPSTvpxRilQQpoGWPEhkdHYdboDh7fN8qoR0ZqFHbNGYfNj41CtFGn2GbdF2mgA4DTxVUY+X9rcO+n21BtsWHj0QLM+uJPbDtehEqF6pH02JlSEy59bhWe+WGvx/fLK62WTS0EgH9//VfA4378u12Y9PrveP/3owG/loiIiC4+VqSISObpK7pCr1Hjpv7eKyrjuiXJHl/buyUsNjv6tY5FtLG2q1+FqSaYtIgwINJLG3THtEGdRo2EyBBsfXw0tBo1Pt5wvK4fBQCw5sBZAEBWfgW6Jh/F/604CAD4fke239dYlHkMc67s5na8rNqCgc+vVmwrH6gvt54CALyy8hDuHNbuvK9HREREFxYrUkQkEx9uwEvX90Sf9MD2w9KoVbi5fzo6JEZAJ9lLSbpGSbonlau2LeSVMMfaq/rcl2lvTqnbsW4pkQpnuvso85jbsY83HK+XECVV39cjIiKiC4NBioguqFLJGqUQhT2WnrmyG/45qgNGdGyh+PpJPZMVjwPAin8NC2gsp4rcN/vtnORfkHp66R7klNS8fsfJYrz26yFsPFoQ0Pv7Q9q0g4iIiIIXp/YR0QUlrfgoVaTGZyQhMTLE4+vnXNkNOrUaS7aedHsuMcLz6wAgMdKAM6W1bc2VglTLmFCv15ByTFO8+s0/fJ77864cTOiuHAKX7sxGl6QIdEiMcHuOBSkiIqLGgRUpIrogVs0ejhev7YGrLkl1Hgt1CVLX9m7pNUQBQGSIDo9d3kXxufAQ5X8LSooMwX9vvASXpEXLjhdWuG+669gbyx+BtDa/59PtyCmpghAC768/inGvrMMzP+zB4o3H8c/P/8SYV9bJ9ugiIiKixoUVKSK6INonhKN9QrjsmEEyte/m/q3w3DXd/bpWVKgOU/q1QnZxFTZlFTjbo2s8tAnf+NgoAECrWCN+2XMGapXnSk8gFalykxUWm/9T7wbOXw2jXuPsBHjgTJns+R0ni9GrleeNkh2O5Vfgg9+zcOewtgEFPyIiIrpwGKSI6KKRTu3LSHXfi8qb+ZNrQtfLKw/itV8P+fWaXq1isGr2MOSXmzH3p73Yfdq92URChMHvMZSbrDhTWu33+QAUW6w7/LovD91To5xTBl0dPVuOn3fnYuEfWcgvN2Pb8SIsu39oQO9PREREFwaDFBFdNAZtbUWqe4BBykG6Ya4/2idEoH0C0LNltGKQkm4eLJUaHSrbsBcA/vHxVjw1qWtA7+9NVkEFnvh+N77YIl//JYSASqXCpNd/lwUxpa6DRERE1DC4RoqILhqDtjYEdVRotOCPEZ1quvs5AtW/x3WCXqNGq3NT3qb0a6X4uj7pylPoXPe20mvU0GvVuLyHcqOIZ3/0vDlvoH76K8ctRAGAyVozfdBbNYuIiIgaFitSRHTRtE8IxwNjOiIt1gi9tm7/jtM5KRLL/jkUiZE1U/LuG9ke04e0gV0IZB4uwJAO8Yqv6+1hLZJass6qe2oUFv39UlSabX5Xf1pEGHC2zCQ71jImFB/f3g+v/XoooI1/HUqqLF733CIiIqKGxyBFRBfVzFEdzvsaXV020XWEjtFdEz2+xluTBp1GBYtNYGL3ZMSFGxAHICHSgB4to/DXqRKvYxnTNRHTh7RBQoQBK/eeQYsIA4Z2qKmaxXiYNuhLSZUFcXV8LREREV0cnNpHRM2Ca4e/UJ0GN/WvmQb448yheOLyLvjH0DbO5w1aDZbOGKK4ifATknbsbePD0K5FOCJCdJjcu6UzRAFAjLE2DH1x5wBnFc2XvFITjpyt8O+DSQghUFJp8X0iERERnTdWpIioWfrzqTHO5hedkiLQKUl5zdby+4fh2gWZKDi3B9VHt/dDfHhtQGodF+bxPWKMteuvUqJCUVJVG3Im907F1mNFmNA9Ce+sPSp73V2fbEVFHdZH/b9fDmDB2iP4/B8DMKBtXMCvJyIiIv+xIkVEzYY0AIXoNFCplPehkmodHyZrYDG0fbysQUWbFp6DlEGyzik2XO/c/0qtAl6+/hKse2gk2rUId3udtxCVU1KFH3ZmQwiBaov8vLfWHIEQwHM/7fP5uYiIiOj8sCJFRM3GuG5J+HTTCUSF6nyfLCHtnqdWq2Qt071t6CtE7S7AYXoNXrmhJ/676hDeuKm387hr10Bfxr2yDqXVVizKPIZtx4sAAP8Y2gaPTqidbrjrdAnyy02ID/d/j6xAOVq0ExERNVesSBFRs/HYxC741+iO+OaegQG9LiNV3twizKDFDzOGYPmsobKW7q66pdTulaVSqXBNr5ZY8++Rss2II0MD+/es0morADhDFAC8tz4Lf52WN8W479PtAAC7XWDrsUIMfn41Fqw5EtB7efLjX9noO3cVMo/k18v1iIiIGiNWpIio2QgzaHH/6MC7Bl51SSoqzTb0axPrPNa9pe8NhTNSo7Dw75cizUvVSlqRahVrxInCSufjDgnhOJRX7tcYr37zD9njTVmFKKm0YM4Pe/Ddn6cBAC8s349vt5/C13f1gxBA5pECdEmJxmurD2FI+xYYn5HkrKJ5qzbN+OxPAMA/P9+BrU+M9mt8RERETQ2DFBGRDxq1CrcMSK/Ta0d2SvD6vHSaYZ/0GGeQurJnCl68rgcuf219nTr4AUDPZ1e4HTuUV46tx4ux9Lgaqzducx5fvPEE/u9vPfHvr3fi2asycOuAdNjtAj/8lY1TRVUoKDfj0YmdodPUTmQorWaHQCIiar44tY+IqAFFhNT+e5Z0yt+N/dIQotNgYDt5970p/dK8Xu+bewahZ1q07JhOI68ubc4qwuoc97/+H/xqJ4QAnvx+NwDglVUHcf8XO/D/fjmAD//IQofHf8b0RVtqr6v2vUYqv9yEM6XVPs8jIiJqbBikiIgaUGSIzlmVmtwrFT1aRuHm/q0wqF08AODBsZ3Qs2UUrrokBa9N6YVHJE0lXP2tT0v0SY/BJ9P7oUNCbTfA7+4dLDvvnfVZPsc198e9eH31Ybfjv+7Pc36tUatgswvc8dFW3PfZdllzDQCw2QWGvvAb+s/7FZVmq8/3JCIiakw4tY+IqAGp1Sqse2gkIIAoow5LZwyRPR9t1ON/Lsc8ST23FisyRIev7x6Ev72TifYJ4chIjcKrN1yCWUt2KL5Oo1Zh+pA2eHdd7X5W7//uO2yVVluxL6cUq/adAVDTzGPRH1m4tHUsxnZLQm5pNarOtWg/eKYcl7hUyoiIiBozVqSIiBpYVKgOUUb/26C/fUsfAEDb+DC8cVMvzJ/cHSM6tcDtQ9rUXtOow4p/DcdbN9ece3WvVHxzzyDn83d3rm3pHhGixd3D26F1nFH2Pq6Plaw9eNb59f/9cgDvrc/CnZ9sgxACJyWNM7Ly/WuaQURE1FiwIkVE1MiMz0jCqtnDkRwVgjBDzV/j0k2DPendKhrPXNkN7eJDUbBvo/N4RIgWsWF6rPn3SKzaewZ3fLwVALDglj6Y8N/1zvNmje6AXq1i0CEhHLcv2oL9uWV4acUB5/OO7oAAcM/i7diUVeB8vDe7FEt3bEbbFuF4bGIXaPxYX0VERBTMGKSIiBqh9pI1UP5SqVSYOqg1LBYLlu2rPd6/TW1Di8s6J+CaXqnQa9TonBSBlKgQZJdUIzZMj1mjOzrPu3t4O8xasgN2+bIop+V7cmWPP/zjGGx2gd8OnMUHv2chJSoEdwxti35tYvHqqoMY3ikBS7acwH0j2sNiF3jh5/2YNboD/tbXe3MNIiKihsIgRUTUTH02/VJ8uyMHT1xe28BCrVbhlRsucT5+97a+eGH5fvx7XCfZayf1SMZnm05g87FCv97L5pK4skuq8cqqg+iUGIGtx4uwal9NE4t7Pt2O7qlROF1chX9//ReWbDmJP08Wo0fLKHxz9yCoVEBOSTWSo0IU97qas3QPlu7Mxg8zhyA12vP+XUREROeLQYqIqJm6tHUMBnXwvs9VRmoUPpne3+24VqPGe1P74pttpzC0QzwKK8x44KudOFVU5XZu56QI7M8tczteVm3F1uNFbsd3nS5xfu14/s8TxXj4m7/w064cVJptuKxzAp6+oitSo0NxrKACizeeQGSIFosyjwEAFm88jofHd4bFZsehM+XokhyBrPwKbDxaiOv7tgQAWO0CITqN189PRETkCYMUERHVSVSoTtbgYsW/hsEugKU7srHhaAGevbIbskuq0CLcgH7zfgUA3DGkDUxWOzolReCJc/tVje2aiHYJ4Viw5ojX9/tq2ynn16v352H1/jwkR4WgqNKMaotddu7poios3ZmNN1YfwsEz5ZjSrxU2ZxXgyNkKbMoqwP6cMpwtN+HLuwbAZgf0WjVsduGcMimEwNlyE47kVWDpzmzklVbjX2M6IiM1ChabHcfyK7DmwFncOjBdMYxVmq0oqbIgKbK2cmazC+fasKIKM95bfxRT+rVCWqwRq/efwaasQozvloRerWLcrlVusmL78SL8vDsXUwe1Rm+XcwAgp6QKQgApHipxBeUm/G9HNv7WtyUiQmqam+w+XYK2LcJg1GthtwuYrHaE6jXIK62GyWpHWqx7w5HCCjOqLDZZxU8I4fyc244XoUW4Aa28NCt5acUB/LovD1ddkoI7hrbFukNnMbBtnF/BVgiBg2fK0SEhHGoPa+1MVhve+u0IRnZOOK9ukRabHWfLTB6/p3RxObZYUKpGEzUEBikiIqoXRn3N/1Ju6t8KN/WvaX4RE6YHALxwbXccyC3HYxO7OH/5Neo1OFNqwu1DWsOg1WDW6A5YfzAfX2875Vw7VVptxYC2sdiUVQjHNlU9Wkbhr1M1VaucEuXNfpfuzMbSndnOx59vPuH8+n87ao+Pfnmd7HU9WkbBbLUrVtA2ZRViUo9k/PhXDspNNftiPbdsH8L0Gtw7sj22HCtEpdmGyBCtc6pi1+RIXN0rBXuzS/H9ufd9aHwnZJ2twFfbTuGtNUeQHmfE8YKaDofvrD2Ka3qlIlSvwZ8nigEAp4oqUW2xwWITzvHfOawtBrSNxSsrD8FstWNy71T834oDsNgEpg1qjXCDFn8cyUdeqQlVFhvGdk3E+kP5OF1chffWH8WoLgkoq7bifzuy0SkxAovv6I/ZX+7AxqMFGNguHpuOFsBktWNyr1Q8dnkXqIUNW86qULLlJBaszUJOSTVGdU6AWq1CjFGHL7eekn2voo06DG4XjwNnar6PfdNjEGbQIre05nWOPcr25pTiy60nceRsBab0a4VJPZIRZtCic1IEthwrRFSoDt1To2Cy2nGsoAJ2O/DhH1n4etspjOmaiOv6tMSaA2cxISMJhRVmHDxThqhQHeb/vB8A8N9fD2HOFV2xdGc2rj23z9rpoioM69gCVRYbth0vwtdbT6F1vBE6jRodEiLQtkUY2ieEIyu/As/+sBe/H87Hu7f2wcjOCdBp1Fi+Oxc/7MxGqzgjBraNw+D28SivtuJEYSXOlleja3IUvt52ErFhBpwtM2H5nlwMaBuLf17WAdFGHQoqzHjt10PIKanGuG5JyC2pgkatRpt4IyrNNrRPCEdsmB4vrTiIdi3CcMfQtiipsuBIXjkiQ3XolBQBnUaNsmoL7vvsT2SkROLOYW0hBFBQYcLSHdnISI3C2G5Jiv9tCCHwzfbTUAEYl5EErVoFjVqFV1YeRJv4MEzu3RLbjhchKlSHt9cewSVp0Zg6qDUA4HBeGdYfyselrWNlG4j78smGY9iXW4bHJnaBVq2q+aOpbRxttwusPXQWH2Ueg1atwoJb+kCnkTeWzsqvwNVv/oEhHeLxxpRebmFq67FCtIwxIikqRHZc+g8YDmXVFkSE6PD++qP4dV8enr6yKzonRXr9DOUmK9YfPIvhnVrAqNficF45Sqos6JUWDbVaBavNjsIKM0xWO2LC9BBCOP/BwvF+ju+/zS5kn9+hqMLs/DvTlwqTFaE6DdRqFUqrLYgM8d351W4XHv/xoaTSElD3WCVZ+RXIK61G/7Zxvk9uIlTCdQfFZqi0tBRRUVEoKSlBZKT3/5AuNIvFgmXLlmHixInQ6c7vhqbmgfcMBaqx3DNVZhs0ahX0WjUOninDuoNnnQFt+qKt2HmqGJXmmjbu867pjst7JGPJlhOY//N+Z+ia3CsVSVEh+HjDcWf4CdGp3SpYFLzaxIchv9yEsuqG3dRZo1ahf5tYZB4pkB0P9H7Sa9UwW/0/f2SnFtiTXYq8MhOAmm0J0mKNWH8o3+vrOiVGYFSXBKzen4doow49WkZj6Y5s5JbK//EhPlyPjokRbp9LakzXRKhVwC97zshel19uRlyYHlddkorUmFCcLTNhzYE8tEsIh8Vqw8q9ZyBQ+4t7tFGH4koL4sP1GNM1EftyylBaZcHR/Aq3z9yjZTTKqq34aVc27AJoGRPq/MeFoR3iMT4jCZ0SI/D74Xx8u/00TpzbbqF3q2ikxhiRV1qNTVk1azh7toyCQatBZKgWJVUWbDtehO4to7HzZLHzPePC9EiODkGoToOOiRHQqFUorrRgaId4xIbp8fLKg9iTXYowvQYdkyKcY4kwaDGpZwoyj+Q7/0EEAEJ1Gkzp1wrbThRh58liDGkfjyt6JuPD348hr6watwxIx9W9UlFpsuHbP0/h6NkK2XYSXZMj0a9NLK7plYq8MhMyj+QjIyUKIToNfj98Fl9tPYV2LcKRHB2CNQfOoltKJGx2ASEAuxAY2qEFQnRqWO0CbePDUFBhxjtrj2BCRjIiQ7WIDNGhzGTF7tMl2H26BKXVVkzsnoSB7eKxL6cU+WUmdEmOREZqFIorzfhpVw5OFVXhcF45hnaIx5R+rfDuuqMoqbI4q74/7cqB2WrHpa1jMKBtHLRqNcIMGmjUKlRb7AgzaDCoXTx2nCyGCoBBp8bqfXnQqFXYlFWIaosNHY1VWDhjfIP/v8nfbNBkgtRbb72F//f//h9ycnLQrVs3vPrqqxg6dKhfr2WQosaM9wwFqqncMyarDRP+ux5CAMv+ORSh+pppYcWVZvx5shixRj16nvsffJXZhiNny53/mm+3C9z43kZsPveL1j+GtsGgdvHYfqIILSIMOFVUhQiDFqkxobiiZwosNjveWH0Yh/PKYRcCY7omIqekGt/9edr5y1OEQYt7RrbDT3/lYE92Kf55WXsYdBosWHPEGeJc3TGkDVrFGVFQbsbUQa0x96e9WLYrB0IA1/Vpic7JNf9Peu6nvai22JEaHQrzuelmQM0vy46qT2p0KLQaFY4XVCI1OhRXXpKCX/bk4ujZCozukgijXuOs0vVvE4ttx4tglTQB0WvVuK5PSxzOK0dajBFHzpZjh+QXTV86J0XgZGElKsy1e5R1T41C1+RILNl6Eka9BinRoTh6thxGvRaL7+iPOUv3eHwPg1YNlQoeQ4o0wBj1GmeolooI0SJUp3GGECVt4sOQ5fKLfH3pmRaNLkkRzmqgN/pzFQqzLbhDvkatcmseQ1RfesTa8c2/GKQuqiVLluDWW2/FW2+9hcGDB+Odd97B+++/j71796JVK997qzBIUWPGe4YC1ZTuGYvNDiFqQkCgSqos+N+O07iyZwqijf5Np1GSW1KNQ3ll6Jsei1C9BlVmG3aeKkb/NrFQqVQoN1mhVatwOK8cFpsdFpuA2WpH39Yxfje7OFlYibfXHsHfB7dB+4Rw7M8tRXGlBQPaxuHI2XKcKKjEgLZxzjDp4LqmJK+sGnmlJmSkRiH73C/2GrUKfxzOxyVp0WjbQt5Wv9piw46TxYgN1SBz/VpcO2kcQgx657Sr3adLYLLa0LtVDFQqFYoqzCiusiDWqEdeWTU6JEYAAA6dKUNiVAgiQ3QwW+3QnJtOVm2xYf2hfMSH67E5qxCpMaEY3SURR86Wo3VcGKx2gdX7z8Bmr+kUKQTwvx2n0SExAn3SY1BusiJMr4Fd1HxWgZo1WnYhYNCq0Sc9FkDN1KqjZyuQc66V/+asAkQb9UiOCsFlnROwZMtJAED/tnGoMFmh16oRGaLDX6eKkRQVgpOFVVCpgDOl1QjVaZAYGYIoow49W0bj6NlynCk1IUSnhkatQlZ+BXq0jEK0UY/4cAMA4MjZcjzzw150T43EqC6J6J4a5fw+lFZbYLMLJEeFQgiBE4WVKDdZERmiw8nCSvzwVzbOlJpwaetYhOrU2H6iZkxFFWaYbXYMaheH9gnhSIwMQWSoDna7QG5pNf6+cIts6muHhHD8Y1hbtIwORZnJilGdE3CisBJPfL8bmUcK8PfBrREXpseWY0XokhyJCRlJKDdZkV9eM11QpQI6Jkbg7hHtUGGyYnNWITZlFSJMr8GJwkpo1WpY7XbEhRuQFmPEqcIKrNl9Al3TEzG5d820yg9+z8KBM2Xo2TIaJqsdsWE6tIoNw6/7zuDw2XLo1GrozwXotFgj1KqatZg//ZWD9Lgw3DogHUWVZqw/lI+9OaXILanGwHZx6N0qBhabHScLKxEfYUCsUQ+VCvhlTy66JkciITIEH/yehbJqC0Z0SkCl2YoQrQZDO8Tjur5p+GV3LrQaFc6WmbDzVAlUAGKMOkSE6LD+0FmUmaxoHReGST2S8cXmk9CoVbiiZwqu7pWCzzadwB+H82G110yrzS6uwrvrj6JVrBEmix3hIVroNWqE6DTIK6tGucmK9Ngw5JVVY8sx92Y7l7aOcR7XqlXnmuKo0b9NHIqrLNBrVEiNDkW/NnHYeqwQOo0a/dvGYm92KWLC9Nh6rBC/HTiL2DA94sP1aBsfjkN5ZThytuYfCxIjDYgM0aFdi5rpq8VVZrRrEY428WHIKzPBZhfQaVTolBiB7JJq7D5dgtPFVdCqVSiqtDjHqVGr8Lc+LTGuWxLWH8rHxxuOoWtKJKw2gfAQLVpEGHC6qApmqx3pcUaE6jU4crYCO08Wo22LMOffiVdfkur8e6tfejSO7d2Oe29o+P83Nasg1b9/f/Tu3RsLFixwHuvSpQuuvvpqzJ8/3+frGaSoMeM9Q4HiPUOB4j3T+DjWBkkbgSgRQiCvzITEyBCP59QF7xnfqi02HM4rR/uEcBRUmBFr1CNUr5Gt66oy26BWAwZt3TuMCiFQZbEhVKepl0YdNruA1W6Xjcnxjxq+rl9hssJ47rxqi032j0nBdM/4mw0afbMJs9mMbdu24ZFHHpEdHzt2LDIzMxVfYzKZYDLVlvlLS0sB1PwALRaL4msuFsf7N/Q4qPHgPUOB4j1DgeI90zjZ3Wc7KooN1dT7z5b3jG8aAJ0SjADsSAjTArDDcm66quNnp1UBEHAeryudCrBa62+doRryMRnU/l1fLzlP43KNYLpn/B1Dow9S+fn5sNlsSExMlB1PTExEbm6u4mvmz5+PZ555xu34ihUrYDR6btd6Ma1cubKhh0CNDO8ZChTvGQoU7xkKFO8ZClQw3DOVlZW+T0ITCFIOrqVEb6XsRx99FLNnz3Y+Li0tRVpaGsaOHRsUU/tWrlyJMWPGNHhZkxoH3jMUKN4zFCjeMxQo3jMUqGC6Zxyz1Xxp9EEqPj4eGo3GrfqUl5fnVqVyMBgMMBgMbsd1Ol2D/+Acgmks1DjwnqFA8Z6hQPGeoUDxnqFABcM94+/7B97mKMjo9Xr06dPHrQy4cuVKDBo0qIFGRURERERETVmjr0gBwOzZs3Hrrbeib9++GDhwIN59912cOHECd999d0MPjYiIiIiImqAmEaRuuOEGFBQU4Nlnn0VOTg4yMjKwbNkypKenN/TQiIiIiIioCWoSQQoA7r33Xtx7770NPQwiIiIiImoGGv0aKSIiIiIioouNQYqIiIiIiChADFJEREREREQBYpAiIiIiIiIKEIMUERERERFRgBikiIiIiIiIAsQgRUREREREFKAms4/U+RBCAABKS0sbeCSAxWJBZWUlSktLodPpGno41AjwnqFA8Z6hQPGeoUDxnqFABdM948gEjozgCYMUgLKyMgBAWlpaA4+EiIiIiIiCQVlZGaKiojw+rxK+olYzYLfbkZ2djYiICKhUqgYdS2lpKdLS0nDy5ElERkY26FioceA9Q4HiPUOB4j1DgeI9Q4EKpntGCIGysjKkpKRArfa8EooVKQBqtRotW7Zs6GHIREZGNvhNRI0L7xkKFO8ZChTvGQoU7xkKVLDcM94qUQ5sNkFERERERBQgBikiIiIiIqIAMUgFGYPBgKeffhoGg6Ghh0KNBO8ZChTvGQoU7xkKFO8ZClRjvGfYbIKIiIiIiChArEgREREREREFiEGKiIiIiIgoQAxSREREREREAWKQIiIiIiIiChCDVJB566230KZNG4SEhKBPnz5Yv359Qw+JGsD8+fNx6aWXIiIiAgkJCbj66qtx4MAB2TlCCMyZMwcpKSkIDQ3FiBEjsGfPHtk5JpMJM2fORHx8PMLCwnDllVfi1KlTF/OjUAOZP38+VCoVZs2a5TzGe4ZcnT59Grfccgvi4uJgNBpxySWXYNu2bc7nec+QlNVqxRNPPIE2bdogNDQUbdu2xbPPPgu73e48h/dM87Zu3TpcccUVSElJgUqlwvfffy97vr7uj6KiItx6662IiopCVFQUbr31VhQXF1/gT6dAUND44osvhE6nE++9957Yu3evuP/++0VYWJg4fvx4Qw+NLrJx48aJhQsXit27d4sdO3aIyy+/XLRq1UqUl5c7z3n++edFRESE+Oabb8SuXbvEDTfcIJKTk0VpaanznLvvvlukpqaKlStXiu3bt4uRI0eKnj17CqvV2hAfiy6SzZs3i9atW4sePXqI+++/33mc9wxJFRYWivT0dDFt2jSxadMmkZWVJVatWiUOHz7sPIf3DEnNnTtXxMXFiR9//FFkZWWJr776SoSHh4tXX33VeQ7vmeZt2bJl4vHHHxfffPONACC+++472fP1dX+MHz9eZGRkiMzMTJGZmSkyMjLEpEmTLtbHdGKQCiL9+vUTd999t+xY586dxSOPPNJAI6JgkZeXJwCItWvXCiGEsNvtIikpSTz//PPOc6qrq0VUVJR4++23hRBCFBcXC51OJ7744gvnOadPnxZqtVosX7784n4AumjKyspEhw4dxMqVK8Xw4cOdQYr3DLl6+OGHxZAhQzw+z3uGXF1++eXi9ttvlx2bPHmyuOWWW4QQvGdIzjVI1df9sXfvXgFAbNy40XnOhg0bBACxf//+C/yp5Di1L0iYzWZs27YNY8eOlR0fO3YsMjMzG2hUFCxKSkoAALGxsQCArKws5Obmyu4Xg8GA4cOHO++Xbdu2wWKxyM5JSUlBRkYG76km7L777sPll1+O0aNHy47zniFXS5cuRd++ffG3v/0NCQkJ6NWrF9577z3n87xnyNWQIUPw66+/4uDBgwCAnTt34vfff8fEiRMB8J4h7+rr/tiwYQOioqLQv39/5zkDBgxAVFTURb+HtBf13cij/Px82Gw2JCYmyo4nJiYiNze3gUZFwUAIgdmzZ2PIkCHIyMgAAOc9oXS/HD9+3HmOXq9HTEyM2zm8p5qmL774Atu3b8eWLVvcnuM9Q66OHj2KBQsWYPbs2XjsscewefNm/POf/4TBYMBtt93Ge4bcPPzwwygpKUHnzp2h0Whgs9nw3HPPYcqUKQD49wx5V1/3R25uLhISEtyun5CQcNHvIQapIKNSqWSPhRBux6h5mTFjBv766y/8/vvvbs/V5X7hPdU0nTx5Evfffz9WrFiBkJAQj+fxniEHu92Ovn37Yt68eQCAXr16Yc+ePViwYAFuu+0253m8Z8hhyZIlWLx4MT777DN069YNO3bswKxZs5CSkoKpU6c6z+M9Q97Ux/2hdH5D3EOc2hck4uPjodFo3JJ0Xl6eW3Kn5mPmzJlYunQpfvvtN7Rs2dJ5PCkpCQC83i9JSUkwm80oKiryeA41Hdu2bUNeXh769OkDrVYLrVaLtWvX4rXXXoNWq3X+zHnPkENycjK6du0qO9alSxecOHECAP+eIXf//ve/8cgjj+DGG29E9+7dceutt+Jf//oX5s+fD4D3DHlXX/dHUlISzpw543b9s2fPXvR7iEEqSOj1evTp0wcrV66UHV+5ciUGDRrUQKOihiKEwIwZM/Dtt99i9erVaNOmjez5Nm3aICkpSXa/mM1mrF271nm/9OnTBzqdTnZOTk4Odu/ezXuqCRo1ahR27dqFHTt2OP/07dsXN998M3bs2IG2bdvyniGZwYMHu22rcPDgQaSnpwPg3zPkrrKyEmq1/FdHjUbjbH/Oe4a8qa/7Y+DAgSgpKcHmzZud52zatAklJSUX/x66qK0tyCtH+/MPPvhA7N27V8yaNUuEhYWJY8eONfTQ6CK75557RFRUlFizZo3Iyclx/qmsrHSe8/zzz4uoqCjx7bffil27dokpU6YothBt2bKlWLVqldi+fbu47LLL2GK2GZF27ROC9wzJbd68WWi1WvHcc8+JQ4cOiU8//VQYjUaxePFi5zm8Z0hq6tSpIjU11dn+/NtvvxXx8fHioYcecp7De6Z5KysrE3/++af4888/BQDx8ssviz///NO5lU993R/jx48XPXr0EBs2bBAbNmwQ3bt3Z/tzEuLNN98U6enpQq/Xi969ezvbXVPzAkDxz8KFC53n2O128fTTT4ukpCRhMBjEsGHDxK5du2TXqaqqEjNmzBCxsbEiNDRUTJo0SZw4ceIifxpqKK5BivcMufrhhx9ERkaGMBgMonPnzuLdd9+VPc97hqRKS0vF/fffL1q1aiVCQkJE27ZtxeOPPy5MJpPzHN4zzdtvv/2m+PvL1KlThRD1d38UFBSIm2++WURERIiIiAhx8803i6Kioov0KWuphBDi4tbAiIiIiIiIGjeukSIiIiIiIgoQgxQREREREVGAGKSIiIiIiIgCxCBFREREREQUIAYpIiIiIiKiADFIERERERERBYhBioiIiIiIKEAMUkRERERERAFikCIiIjpPKpUK33//fUMPg4iILiIGKSIiatSmTZsGlUrl9mf8+PENPTQiImrCtA09ACIiovM1fvx4LFy4UHbMYDA00GiIiKg5YEWKiIgaPYPBgKSkJNmfmJgYADXT7hYsWIAJEyYgNDQUbdq0wVdffSV7/a5du3DZZZchNDQUcXFxuPPOO1FeXi4758MPP0S3bt1gMBiQnJyMGTNmyJ7Pz8/HNddcA6PRiA4dOmDp0qUX9kMTEVGDYpAiIqIm78knn8S1116LnTt34pZbbsGUKVOwb98+AEBlZSXGjx+PmJgYbNmyBV999RVWrVolC0oLFizAfffdhzvvvBO7du3C0qVL0b59e9l7PPPMM7j++uvx119/YeLEibj55ptRWFh4UT8nERFdPCohhGjoQRAREdXVtGnTsHjxYoSEhMiOP/zww3jyySehUqlw9913Y8GCBc7nBgwYgN69e+Ott97Ce++9h4cffhgnT55EWFgYAGDZsmW44oorkJ2djcTERKSmpuLvf/875s6dqzgGlUqFJ554Av/5z38AABUVFYiIiMCyZcu4VouIqIniGikiImr0Ro4cKQtKABAbG+v8euDAgbLnBg4ciB07dgAA9u3bh549ezpDFAAMHjwYdrsdBw4cgEqlQnZ2NkaNGuV1DD169HB+HRYWhoiICOTl5dX1IxERUZBjkCIiokYvLCzMbaqdLyqVCgAghHB+rXROaGioX9fT6XRur7Xb7QGNiYiIGg+ukSIioiZv48aNbo87d+4MAOjatSt27NiBiooK5/N//PEH1Go1OnbsiIiICLRu3Rq//vrrRR0zEREFN1akiIio0TOZTMjNzZUd02q1iI+PBwB89dVX6Nu3L4YMGYJPP/0UmzdvxgcffAAAuPnmm/H0009j6tSpmDNnDs6ePYuZM2fi1ltvRWJiIgBgzpw5uPvuu5GQkIAJEyagrKwMf/zxB2bOnHlxPygREQUNBikiImr0li9fjuTkZNmxTp06Yf/+/QBqOup98cUXuPfee5GUlIRPP/0UXbt2BQAYjUb88ssvuP/++3HppZfCaDTi2muvxcsvv+y81tSpU1FdXY1XXnkFDz74IOLj43HdddddvA9IRERBh137iIioSVOpVPjuu+9w9dVXN/RQiIioCeEaKSIiIiIiogAxSBEREREREQWIa6SIiKhJ4wx2IiK6EFiRIiIiIiIiChCDFBERERERUYAYpIiIiIiIiALEIEVERERERBQgBikiIiIiIqIAMUgREREREREFiEGKiIiIiIgoQAxSREREREREAfr/m+rwC97CwZAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0d9a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1527\n",
      "F1 Score: 0.6152\n",
      "Precision: 0.6095\n",
      "Recall: 0.6234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "avg_loss, f1, precision, recall, all_preds, all_labels, all_ids = test_epoch(\n",
    "    model, \n",
    "    loader_val, \n",
    "    criterion, \n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b62f0",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a983b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clips = pd.read_parquet(DATA_ROOT / \"test/segments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fffe6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset\n",
    "dataset_te = EEGDataset(\n",
    "    test_clips,  # Your test clips variable\n",
    "    signals_root=DATA_ROOT\n",
    "    / \"test\",  # Update this path if your test signals are stored elsewhere\n",
    "    signal_transform=_hjorth_transform,  # You can change or remove the signal_transform as needed\n",
    "    prefetch=True,  # Set to False if prefetching causes memory issues on your compute environment\n",
    "    return_id=True,  # Return the id of each sample instead of the label\n",
    ")\n",
    "\n",
    "# Create DataLoader for the test dataset\n",
    "loader_te = DataLoader(dataset_te, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbc8d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(model, test_loader, single_graph_edge_index, device, output_filename=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Generates a Kaggle submission file for the GAT model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained GATClassifier model.\n",
    "        test_loader (DataLoader): DataLoader for the test set. It must yield\n",
    "                                  batches of (x_batch, ids_batch).\n",
    "        single_graph_edge_index (torch.Tensor): The pre-computed edge_index for a single graph.\n",
    "        device (torch.device): The device to run inference on (e.g., 'cuda' or 'cpu').\n",
    "        output_filename (str): The name of the output CSV file.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_ids = []\n",
    "\n",
    "    # Move the single-graph edge_index to the correct device once\n",
    "    edge_index_template = single_graph_edge_index.to(device)\n",
    "\n",
    "    # Disable gradient computation for faster inference\n",
    "    with torch.no_grad():\n",
    "        for x_batch, ids_batch in tqdm(test_loader, desc=\"Generating Submission\"):\n",
    "            # x_batch shape: (batch_size, num_nodes, num_features)\n",
    "            \n",
    "            x_batch = x_batch.float().to(device)\n",
    "            B, N, F = x_batch.shape\n",
    "\n",
    "            # --- On-the-fly Batch Conversion for GAT model ---\n",
    "            x_pyg = x_batch.reshape(-1, F)\n",
    "            batch_vector = torch.arange(B, device=device).repeat_interleave(N)\n",
    "            edge_indices = [edge_index_template + i * N for i in range(B)]\n",
    "            batched_edge_index = torch.cat(edge_indices, dim=1)\n",
    "            # --- Conversion Complete ---\n",
    "\n",
    "            # Forward pass to get model logits\n",
    "            # We only need the logits, so we discard the attention weights with `_`\n",
    "            logits, _ = model(x_pyg, batched_edge_index, batch_vector)\n",
    "\n",
    "            # Convert logits to binary predictions (0 or 1)\n",
    "            # A logit > 0 corresponds to a probability > 0.5 after sigmoid\n",
    "            predictions = (logits > 0).int().cpu().squeeze().tolist()\n",
    "\n",
    "            # Ensure predictions are in a list, even for a single-item batch\n",
    "            if not isinstance(predictions, list):\n",
    "                predictions = [predictions]\n",
    "\n",
    "            # Store predictions and their corresponding IDs\n",
    "            all_predictions.extend(predictions)\n",
    "            all_ids.extend(list(ids_batch))\n",
    "\n",
    "    # Create a DataFrame for the submission file\n",
    "    print(\"Creating submission DataFrame...\")\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": all_ids,\n",
    "        \"label\": all_predictions\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Submission file saved successfully to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02458e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Submission: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 108.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission DataFrame...\n",
      "Submission file saved successfully to: gat_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Create the DataLoader for the test set\n",
    "#    shuffle=False is crucial for submission.\n",
    "loader_te = DataLoader(dataset_te, batch_size=512, shuffle=False)\n",
    "\n",
    "# 4. Call the function to generate the file\n",
    "#    Ensure your model, single_graph_edge_index, and device are defined\n",
    "generate_submission_file(\n",
    "    model=model,\n",
    "    test_loader=loader_te,\n",
    "    single_graph_edge_index=single_graph_edge_index, # The same one used for training\n",
    "    device=device,\n",
    "    output_filename=\"gat_submission.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c6f5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the gat_submission.csv file lines from p_q_e_j_g_v_e_j___s_0_0_1___t_0_0_0___1_5_7 to pqejgvej_s001_t000_157 format\n",
    "def format_submission_ids(submission_file):\n",
    "    \"\"\"\n",
    "    Formats the IDs in the submission file to the required format.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(submission_file)\n",
    "    \n",
    "    # Define a function to format each ID\n",
    "    def format_id(id_str):\n",
    "        parts = id_str.split(\"___\")\n",
    "        parts = [part.replace(\"_\", \"\") for part in parts]\n",
    "        return \"_\".join(parts)\n",
    "    \n",
    "    # Apply the formatting function to the 'id' column\n",
    "    df['id'] = df['id'].apply(format_id)\n",
    "    \n",
    "    # Save the formatted DataFrame back to CSV\n",
    "    df.to_csv(submission_file, index=False)\n",
    "    print(f\"Formatted submission file saved successfully to: {submission_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ff95792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted submission file saved successfully to: gat_submission.csv\n"
     ]
    }
   ],
   "source": [
    "format_submission_ids(\"gat_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0c609",
   "metadata": {},
   "source": [
    "## K-Fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "714cf3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/stnikoli/nml_project/\")\n",
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c185f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Fold 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:13<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.5192\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Fold 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:29<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.5748\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Fold 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:40<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.5494\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Fold 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:15<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.4733\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Fold 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [05:58<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.5710\n",
      "Cross-Validation Average F1 Score: 0.5375\n",
      "Cross-Validation F1 Score Standard Deviation: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dt in [np.inf]:\n",
    "    single_graph_edge_index = create_graph_edge_index(\n",
    "        distances_path=DATA_ROOT / \"distances_3d.csv\",\n",
    "        distance_threshold = dt\n",
    "    )\n",
    "    # Move the single-graph edge_index to the correct device once\n",
    "    edge_index_template = single_graph_edge_index.to(device)\n",
    "    avg_f1_score, std_f1_score = evaluate(\n",
    "        model=GATClassifier,\n",
    "        clips=clips_tr,\n",
    "        signals_root=DATA_ROOT / \"train\",\n",
    "        num_epochs=1000,\n",
    "        learning_rate=1e-4,\n",
    "        batch_size=512,\n",
    "        threshold=0.5,\n",
    "        prefetch=True,\n",
    "        signal_transform=_hjorth_transform,\n",
    "        model_args={\"num_node_features\": 15, \"num_classes\": 1, \"edge_index_template\": edge_index_template, \"evaluate\":True},\n",
    "        criterion=nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weight], device=device)),\n",
    "        k_folds=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bb9a0",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03ee551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATClassifier(num_node_features=15, num_classes=1, edge_index_template=edge_index_template) # num_classes=1 for BCEWithLogitsLoss\n",
    "\n",
    "# Or load a pre-trained model if available\n",
    "model.load_state_dict(torch.load(BASE_DIR + \"/run_all_edges/gat_model_epoch_1000.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd604c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may need to adjust this list to match the order in your dataset\n",
    "ELECTRODE_LABELS = [\n",
    "    'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "    'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz'\n",
    "]\n",
    "\n",
    "# Define approximate 10-20 system 2D coordinates for the electrodes\n",
    "# These are relative coordinates; you can adjust the scaling as needed.\n",
    "# (x, y) coordinates: x is left-right, y is front-back\n",
    "# (0,0) is roughly Cz\n",
    "ELECTRODE_POSITIONS = {\n",
    "    'Fp1': (-0.3, 1.0), 'Fp2': (0.3, 1.0),\n",
    "    'F3': (-0.4, 0.6), 'F4': (0.4, 0.6),\n",
    "    'C3': (-0.5, 0.0), 'C4': (0.5, 0.0),\n",
    "    'P3': (-0.4, -0.6), 'P4': (0.4, -0.6),\n",
    "    'O1': (-0.2, -1.0), 'O2': (0.2, -1.0),\n",
    "    'F7': (-0.6, 0.4), 'F8': (0.6, 0.4),\n",
    "    'T3': (-0.8, 0.0), 'T4': (0.8, 0.0),\n",
    "    'T5': (-0.6, -0.4), 'T6': (0.6, -0.4),\n",
    "    'Fz': (0.0, 0.75),\n",
    "    'Cz': (0.0, 0.0),\n",
    "    'Pz': (0.0, -0.75)\n",
    "}\n",
    "\n",
    "# Ensure all labels in ELECTRODE_LABELS have a corresponding position\n",
    "# This is a good sanity check\n",
    "for label in ELECTRODE_LABELS:\n",
    "    if label not in ELECTRODE_POSITIONS:\n",
    "        print(f\"Warning: Electrode {label} missing from ELECTRODE_POSITIONS. It won't be plotted correctly.\")\n",
    "\n",
    "\n",
    "def get_average_attention(model, loader, device, edge_index_template):\n",
    "    \"\"\"\n",
    "    Runs the model on the dataset and computes the average attention weights\n",
    "    for seizure and non-seizure classes.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    seizure_attention_sum = 0\n",
    "    non_seizure_attention_sum = 0\n",
    "    seizure_count = 0\n",
    "    non_seizure_count = 0\n",
    "\n",
    "    num_nodes = len(ELECTRODE_LABELS)\n",
    "    num_edges = edge_index_template.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(loader, desc=\"Extracting Attention\", leave=False):\n",
    "            x_batch = x_batch.float().to(device)\n",
    "            B = x_batch.shape[0]\n",
    "\n",
    "            # Get model output and attention weights\n",
    "            _, attention_weights_tuple = model(x_batch)\n",
    "\n",
    "            # attention_weights_tuple is (edge_index, attention_scores)\n",
    "            # attention_scores shape: [num_total_edges, num_heads]\n",
    "            attention_scores = attention_weights_tuple[1]\n",
    "\n",
    "            # Average across attention heads -> [num_total_edges, 1]\n",
    "            attention_scores = attention_scores.mean(dim=1)\n",
    "\n",
    "            # Reshape to match batch structure: (B, num_edges_per_graph)\n",
    "            attention_per_graph = attention_scores.reshape(B, num_edges)\n",
    "\n",
    "            for i in range(B):\n",
    "                label = y_batch[i].item()\n",
    "                if label == 1:\n",
    "                    seizure_attention_sum += attention_per_graph[i]\n",
    "                    seizure_count += 1\n",
    "                else:\n",
    "                    non_seizure_attention_sum += attention_per_graph[i]\n",
    "                    non_seizure_count += 1\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_seizure_attention = seizure_attention_sum / seizure_count if seizure_count > 0 else torch.zeros(num_edges)\n",
    "    avg_non_seizure_attention = non_seizure_attention_sum / non_seizure_count if non_seizure_count > 0 else torch.zeros(num_edges)\n",
    "\n",
    "    return avg_seizure_attention.cpu().numpy(), avg_non_seizure_attention.cpu().numpy()\n",
    "\n",
    "def plot_attention_graph(avg_attention_scores, edge_index, title, output_path=BASE_DIR + \"/images/attention_graph.png\", percentile_threshold=90.0):\n",
    "    \"\"\"\n",
    "    Visualizes the average attention weights on a graph of electrodes with 10-20 system-like positioning.\n",
    "\n",
    "    Args:\n",
    "        avg_attention_scores (np.array): Array of attention scores for each edge.\n",
    "        edge_index (torch.Tensor): The graph's edge_index.\n",
    "        title (str): The title for the plot.\n",
    "        percentile_threshold (float): The percentile to use as a threshold for displaying\n",
    "                                      edges (e.g., 90.0 for top 10%).\n",
    "    \"\"\"\n",
    "    if np.sum(avg_attention_scores) == 0:\n",
    "        print(f\"Skipping plot for '{title}': No samples found or attention is zero.\")\n",
    "        return\n",
    "\n",
    "    # 1. Calculate the score threshold based on the desired percentile\n",
    "    if percentile_threshold > 0:\n",
    "        threshold = np.percentile(avg_attention_scores, percentile_threshold)\n",
    "    else:\n",
    "        threshold = 0 # If threshold is 0, show all edges\n",
    "\n",
    "    # 2. Create a boolean mask for edges with scores above the threshold\n",
    "    mask = avg_attention_scores >= threshold\n",
    "\n",
    "    # 3. Filter the edges and their scores using the mask\n",
    "    top_edges_index = edge_index[:, mask]\n",
    "    top_scores = avg_attention_scores[mask]\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Create a graph containing ALL nodes, but only the TOP edges\n",
    "    g = nx.Graph()\n",
    "    # Add nodes with their corresponding labels as node attributes\n",
    "    for i, label in enumerate(ELECTRODE_LABELS):\n",
    "        g.add_node(i, label=label) # Store label as node attribute\n",
    "\n",
    "    top_edges_list = top_edges_index.t().cpu().numpy()\n",
    "    g.add_edges_from(top_edges_list)\n",
    "\n",
    "    # Create the 'pos' dictionary using the predefined ELECTRODE_POSITIONS\n",
    "    pos = {i: ELECTRODE_POSITIONS[ELECTRODE_LABELS[i]] for i in range(len(ELECTRODE_LABELS))}\n",
    "\n",
    "    # --- Color mapping setup ---\n",
    "    # IMPORTANT: Normalize based on the original full range of scores for correct color representation\n",
    "    vmin = np.min(avg_attention_scores)\n",
    "    vmax = np.max(avg_attention_scores)\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = plt.cm.viridis\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # Map the TOP scores to RGBA colors\n",
    "    edge_colors = sm.to_rgba(top_scores)\n",
    "\n",
    "    # Scale edge widths based on the TOP scores\n",
    "    edge_widths = top_scores * 15 # Adjust multiplier for desired width\n",
    "\n",
    "    # Draw all nodes\n",
    "    nodes = nx.draw_networkx_nodes(g, pos, node_color='lightblue', node_size=1000)\n",
    "\n",
    "    # Draw only the TOP edges\n",
    "    edges = nx.draw_networkx_edges(\n",
    "        g,\n",
    "        pos,\n",
    "        edgelist=top_edges_list, # Explicitly provide the list of top edges\n",
    "        edge_color=edge_colors,\n",
    "        width=edge_widths,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Use the labels stored as node attributes\n",
    "    labels = {i: g.nodes[i]['label'] for i in g.nodes()}\n",
    "    nx.draw_networkx_labels(g, pos, labels=labels, font_size=10, font_weight='bold')\n",
    "\n",
    "    cbar = plt.colorbar(sm, shrink=0.8)\n",
    "    cbar.set_label('Attention Weight (Full Range)', weight='bold')\n",
    "\n",
    "    plt.title(f\"{title}\\n(Displaying Top {100 - percentile_threshold:.0f}% Edges)\", size=16, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    # save plot\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f4af98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating attention visualizations...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loader_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the average attention weights from the validation set\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# We use loader_val because it's an unseen sample of the data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m avg_seizure_attn, avg_non_seizure_attn \u001b[38;5;241m=\u001b[39m get_average_attention(model, \u001b[43mloader_val\u001b[49m, device, edge_index_template)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# The edge_index_template is the graph structure for a single sample\u001b[39;00m\n\u001b[1;32m     15\u001b[0m single_graph_edge_index \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39medge_index_template\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader_val' is not defined"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 5. Interpretation and Visualization\n",
    "# ======================================================================\n",
    "\n",
    "print(\"Generating attention visualizations...\")\n",
    "\n",
    "# Ensure your model is on the correct device\n",
    "model.to(device)\n",
    "\n",
    "# Get the average attention weights from the validation set\n",
    "# We use loader_val because it's an unseen sample of the data\n",
    "avg_seizure_attn, avg_non_seizure_attn = get_average_attention(model, loader_val, device, edge_index_template)\n",
    "\n",
    "# The edge_index_template is the graph structure for a single sample\n",
    "single_graph_edge_index = model.edge_index_template\n",
    "\n",
    "# Plot the graph for the \"Non-Seizure\" class\n",
    "plot_attention_graph(\n",
    "    avg_non_seizure_attn, \n",
    "    single_graph_edge_index, \n",
    "    title=\"Average Attention for Non-Seizure Class\",\n",
    "    output_path=BASE_DIR + \"/images/attention_graph_non_seizure.png\",\n",
    ")\n",
    "\n",
    "# Plot the graph for the \"Seizure\" class\n",
    "plot_attention_graph(\n",
    "    avg_seizure_attn, \n",
    "    single_graph_edge_index, \n",
    "    title=\"Average Attention for Seizure Class\",\n",
    "    output_path=BASE_DIR + \"/images/attention_graph_seizure.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818972b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
